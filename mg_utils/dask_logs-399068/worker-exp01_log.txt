RUNNING: "python -m dask_cuda.cli.dask_cuda_worker --rmm-pool-size=12G
             --local-directory=/tmp/
             --scheduler-file=/root/cugraph/mg_utils/dask-scheduler.json
             --memory-limit=auto
             --device-memory-limit=auto
            "
2023-06-26 18:53:07,178 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:35225'
2023-06-26 18:53:07,181 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:42143'
2023-06-26 18:53:07,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:39027'
2023-06-26 18:53:07,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:45993'
2023-06-26 18:53:07,187 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:38111'
2023-06-26 18:53:07,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:32963'
2023-06-26 18:53:07,193 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:43735'
2023-06-26 18:53:07,194 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:44863'
2023-06-26 18:53:07,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:46481'
2023-06-26 18:53:07,199 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:44653'
2023-06-26 18:53:07,200 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:40083'
2023-06-26 18:53:07,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:34195'
2023-06-26 18:53:07,205 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:41017'
2023-06-26 18:53:07,207 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:32883'
2023-06-26 18:53:07,209 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:44101'
2023-06-26 18:53:07,212 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:39011'
2023-06-26 18:53:08,786 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,786 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,871 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,871 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,874 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,874 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,880 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,891 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,891 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,893 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,893 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,920 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,920 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,922 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,922 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,924 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,924 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,930 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,930 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,932 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,932 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,933 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,933 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,944 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,944 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,945 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:53:08,945 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:53:08,962 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,046 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,049 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,049 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,050 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,057 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,070 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,070 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,099 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,100 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,101 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,109 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,110 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,111 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,118 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:09,123 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:53:15,488 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:34257
2023-06-26 18:53:15,488 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:34257
2023-06-26 18:53:15,488 - distributed.worker - INFO -          dashboard at:        10.120.104.11:45027
2023-06-26 18:53:15,488 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,488 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,488 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,488 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,488 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fz705dcs
2023-06-26 18:53:15,489 - distributed.worker - INFO - Starting Worker plugin RMMSetup-db93d265-6821-4bb9-b7b5-d0f711da3bf4
2023-06-26 18:53:15,501 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:43879
2023-06-26 18:53:15,501 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:43879
2023-06-26 18:53:15,501 - distributed.worker - INFO -          dashboard at:        10.120.104.11:41733
2023-06-26 18:53:15,501 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,501 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,501 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,502 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,502 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qssltu60
2023-06-26 18:53:15,502 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d3f8f555-751d-404f-a8aa-7749fe9190a2
2023-06-26 18:53:15,588 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:40815
2023-06-26 18:53:15,589 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:40815
2023-06-26 18:53:15,589 - distributed.worker - INFO -          dashboard at:        10.120.104.11:42767
2023-06-26 18:53:15,589 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,589 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,589 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,589 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8jvm6cu9
2023-06-26 18:53:15,590 - distributed.worker - INFO - Starting Worker plugin PreImport-caaec8fc-2897-4c75-8967-29a08eeccbb1
2023-06-26 18:53:15,590 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a7139ddd-127e-47c6-afd5-80965d0b07d5
2023-06-26 18:53:15,594 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:34613
2023-06-26 18:53:15,595 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:34613
2023-06-26 18:53:15,595 - distributed.worker - INFO -          dashboard at:        10.120.104.11:37813
2023-06-26 18:53:15,595 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,595 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,595 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,595 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,595 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sbg2ifia
2023-06-26 18:53:15,595 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20b97c0d-838a-4fa2-8d56-57f4a128dbf2
2023-06-26 18:53:15,612 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:41499
2023-06-26 18:53:15,612 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:41499
2023-06-26 18:53:15,612 - distributed.worker - INFO -          dashboard at:        10.120.104.11:44067
2023-06-26 18:53:15,612 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,612 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,612 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,612 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,612 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_0ahcd1m
2023-06-26 18:53:15,612 - distributed.worker - INFO - Starting Worker plugin PreImport-f72362f1-b54b-4bbf-baae-2c914bf77213
2023-06-26 18:53:15,613 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab1ce871-f11c-4078-9797-fc946193f64e
2023-06-26 18:53:15,648 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:46113
2023-06-26 18:53:15,648 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:46113
2023-06-26 18:53:15,648 - distributed.worker - INFO -          dashboard at:        10.120.104.11:45233
2023-06-26 18:53:15,648 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,648 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,648 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,649 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,649 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1bbmvwfu
2023-06-26 18:53:15,649 - distributed.worker - INFO - Starting Worker plugin RMMSetup-20f3eec5-82dd-4a61-8e3d-ffb2e7d1ee3f
2023-06-26 18:53:15,662 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:34603
2023-06-26 18:53:15,662 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:34603
2023-06-26 18:53:15,663 - distributed.worker - INFO -          dashboard at:        10.120.104.11:35857
2023-06-26 18:53:15,663 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,663 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,663 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,663 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,663 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y5d8dxlb
2023-06-26 18:53:15,663 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3edefcda-282e-4df9-93c3-1fb89872394f
2023-06-26 18:53:15,663 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b62cd77e-854e-4827-a1f8-b94afac51cdf
2023-06-26 18:53:15,811 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:37443
2023-06-26 18:53:15,811 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:37443
2023-06-26 18:53:15,811 - distributed.worker - INFO -          dashboard at:        10.120.104.11:36171
2023-06-26 18:53:15,811 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,811 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,812 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,812 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,812 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-thesn95l
2023-06-26 18:53:15,812 - distributed.worker - INFO - Starting Worker plugin PreImport-2bfcd736-2e06-4834-ac18-14d4f5453529
2023-06-26 18:53:15,812 - distributed.worker - INFO - Starting Worker plugin RMMSetup-121d7994-166f-471d-a905-9bb32ee37ec8
2023-06-26 18:53:15,850 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44785
2023-06-26 18:53:15,850 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44785
2023-06-26 18:53:15,850 - distributed.worker - INFO -          dashboard at:        10.120.104.11:38213
2023-06-26 18:53:15,850 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:15,850 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:15,850 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:15,850 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:15,850 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kdoy5lwt
2023-06-26 18:53:15,851 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1464924a-5561-41e7-b371-c5c7e0e5513a
2023-06-26 18:53:16,051 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5485e953-89cd-4438-9cb3-f68b92a01883
2023-06-26 18:53:16,051 - distributed.worker - INFO - Starting Worker plugin PreImport-5c9e1f0c-ec1a-484b-9518-dcb94a387e17
2023-06-26 18:53:16,051 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,075 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,076 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,079 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,100 - distributed.worker - INFO - Starting Worker plugin PreImport-2c306c9c-f53e-4ffa-94b1-02f7d41a19ce
2023-06-26 18:53:16,100 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-51f3bd5e-4b57-451d-8f36-67791ad38634
2023-06-26 18:53:16,101 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,120 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,120 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,124 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,145 - distributed.worker - INFO - Starting Worker plugin PreImport-593675d6-f6d0-4c30-b9b9-928156d85584
2023-06-26 18:53:16,146 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3a8b84b1-8dd7-4ff8-b805-eba28d506d01
2023-06-26 18:53:16,146 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,164 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-68b4f334-0ac2-43f7-995f-ced88422c0c5
2023-06-26 18:53:16,165 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,169 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,169 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,172 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,177 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44743
2023-06-26 18:53:16,177 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44743
2023-06-26 18:53:16,177 - distributed.worker - INFO -          dashboard at:        10.120.104.11:36939
2023-06-26 18:53:16,177 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,177 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,177 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,177 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,177 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f6cjki9x
2023-06-26 18:53:16,178 - distributed.worker - INFO - Starting Worker plugin PreImport-a7f4bd03-c25e-4d49-b4c6-357dd2fb4194
2023-06-26 18:53:16,178 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dcee340d-5d35-4530-8521-61b2ee4e2b40
2023-06-26 18:53:16,184 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:36615
2023-06-26 18:53:16,184 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:36615
2023-06-26 18:53:16,184 - distributed.worker - INFO -          dashboard at:        10.120.104.11:35157
2023-06-26 18:53:16,184 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,184 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,184 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,184 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,184 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dwglvfkw
2023-06-26 18:53:16,185 - distributed.worker - INFO - Starting Worker plugin PreImport-6cae9eac-0710-41cd-b301-ebbaaa361a25
2023-06-26 18:53:16,185 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3cc5ee73-f847-4bce-8797-b8e25dd83cf5
2023-06-26 18:53:16,188 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:35255
2023-06-26 18:53:16,188 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:35255
2023-06-26 18:53:16,188 - distributed.worker - INFO -          dashboard at:        10.120.104.11:36865
2023-06-26 18:53:16,188 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,188 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,188 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,188 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,188 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y4iwys85
2023-06-26 18:53:16,188 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7959e18b-fa12-4772-b583-c2df1a35285d
2023-06-26 18:53:16,189 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,189 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,191 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,221 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-53a0a431-2d35-4d45-aba9-2b05bc2e5cbe
2023-06-26 18:53:16,224 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,224 - distributed.worker - INFO - Starting Worker plugin PreImport-c859838f-ff73-45ed-b3a4-933a4ecff179
2023-06-26 18:53:16,224 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-38e97853-6437-4bbc-ae1f-37915f271077
2023-06-26 18:53:16,225 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,231 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:45235
2023-06-26 18:53:16,231 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:45235
2023-06-26 18:53:16,231 - distributed.worker - INFO -          dashboard at:        10.120.104.11:43017
2023-06-26 18:53:16,231 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,231 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,231 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,232 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,232 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-q9m2xhuq
2023-06-26 18:53:16,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f48c7c1e-da2e-446f-b510-4e78fe86e194
2023-06-26 18:53:16,234 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44865
2023-06-26 18:53:16,234 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44865
2023-06-26 18:53:16,234 - distributed.worker - INFO -          dashboard at:        10.120.104.11:35179
2023-06-26 18:53:16,234 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,234 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,234 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,234 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,234 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uzgl4rx0
2023-06-26 18:53:16,235 - distributed.worker - INFO - Starting Worker plugin PreImport-2556f22a-6978-4ede-8c4a-20d1a35c93b9
2023-06-26 18:53:16,235 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7bf5789d-8c98-42fc-8e2f-040bcdb0a8ba
2023-06-26 18:53:16,237 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,237 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,241 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,241 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,242 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,249 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,250 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:41585
2023-06-26 18:53:16,250 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:41585
2023-06-26 18:53:16,250 - distributed.worker - INFO -          dashboard at:        10.120.104.11:38581
2023-06-26 18:53:16,250 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,250 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,250 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,250 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,250 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9q9yajuq
2023-06-26 18:53:16,251 - distributed.worker - INFO - Starting Worker plugin PreImport-69e40d5a-c92b-4abf-802e-3afaa80fb032
2023-06-26 18:53:16,251 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c91d3b07-d7eb-4e75-8c45-a36f49ad08b4
2023-06-26 18:53:16,254 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:34885
2023-06-26 18:53:16,255 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:34885
2023-06-26 18:53:16,255 - distributed.worker - INFO -          dashboard at:        10.120.104.11:40377
2023-06-26 18:53:16,255 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,255 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,255 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:53:16,255 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:53:16,255 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z4uzh4kb
2023-06-26 18:53:16,255 - distributed.worker - INFO - Starting Worker plugin PreImport-fcb97d6a-241a-4b7e-8513-9d440143ceae
2023-06-26 18:53:16,255 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6dec9b06-1734-4662-9d38-f8da39524668
2023-06-26 18:53:16,323 - distributed.worker - INFO - Starting Worker plugin PreImport-781f54ee-1e07-470c-ab13-b9142ae685c1
2023-06-26 18:53:16,325 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,349 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,350 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,352 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,390 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c3f634c3-bdaa-4e44-a647-4b733a51a746
2023-06-26 18:53:16,391 - distributed.worker - INFO - Starting Worker plugin PreImport-1c16c722-15e1-41b3-b604-a9fbb9044502
2023-06-26 18:53:16,392 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,410 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,410 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,418 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,426 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-29f0407d-4530-4c90-8de0-30db05cb8959
2023-06-26 18:53:16,427 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,442 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,443 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,450 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,501 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ab6b8dbf-b9ea-40cf-82aa-ba428eb34629
2023-06-26 18:53:16,501 - distributed.worker - INFO - Starting Worker plugin PreImport-4ae48cea-166d-45e2-822d-ce5f4fa55eca
2023-06-26 18:53:16,501 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-53df61d6-3b38-4cb0-bd08-f08cf8a67549
2023-06-26 18:53:16,502 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,502 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-cbd831e7-1cb6-4a5b-ade6-f49f464caf1b
2023-06-26 18:53:16,502 - distributed.worker - INFO - Starting Worker plugin PreImport-8cf1c185-0fda-45ac-ad89-d790932a3c11
2023-06-26 18:53:16,503 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,503 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,514 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,514 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,515 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,515 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,515 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,516 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,518 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,518 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,520 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,567 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-32451e36-cbe7-49b8-86f1-aced23ec6103
2023-06-26 18:53:16,567 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2b40a20d-25bc-467a-a22b-480466cf47fc
2023-06-26 18:53:16,567 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4f7908fd-e693-4dd1-864f-1fba83fe8401
2023-06-26 18:53:16,568 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-150615be-9f8d-40c3-9d15-6ddc8c1e4f7b
2023-06-26 18:53:16,568 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,568 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,568 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,569 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,606 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,606 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,607 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,607 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,607 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,607 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,607 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,608 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:53:16,608 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:53:16,609 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,610 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:16,611 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,792 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,795 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,795 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,795 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,796 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,796 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,796 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,797 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,797 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,806 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,807 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,807 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,807 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,807 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,807 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:23,807 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:24,482 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:53:38,975 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,168 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,226 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,297 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,298 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,468 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,511 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,569 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,617 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,628 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,664 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,665 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,716 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,778 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,813 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:39,818 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:53:45,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:53:45,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:23,911 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,911 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,915 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,915 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,915 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,918 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,918 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,918 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,918 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,918 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,919 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,919 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,920 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,922 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,922 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:23,923 - distributed.worker - INFO - Run out-of-band function 'collect'
2023-06-26 18:54:27,134 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,140 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,141 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,141 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,141 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,141 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:27,885 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,891 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:27,900 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,900 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,900 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,900 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,900 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:27,901 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,138 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,139 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,139 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,149 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,150 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,951 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,952 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,952 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,952 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,952 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,952 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,952 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,962 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:30,963 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,728 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,729 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,740 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:31,741 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,519 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,520 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,520 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,520 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,520 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,520 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,520 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,524 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,533 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,534 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,534 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:32,534 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,342 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,353 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:33,354 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,177 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,178 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,178 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:34,188 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,188 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,188 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,188 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,188 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,188 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:34,189 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,007 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,018 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,019 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,022 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,943 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,944 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,944 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,944 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:35,955 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,761 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:36,772 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,772 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,772 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:36,773 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,500 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,500 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,500 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,501 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,512 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,513 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,513 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,513 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,513 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,513 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,513 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:54:37,837 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,837 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,837 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,838 - distributed.worker - INFO - Run out-of-band function '_get_allocation_counts'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,851 - distributed.worker - INFO - Run out-of-band function 'set_statistics_adaptor'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,866 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:37,867 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:54:41,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:54:42,426 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,428 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:34257. Reason: scheduler-restart
2023-06-26 18:54:42,428 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,429 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,429 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,430 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,430 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:34603. Reason: scheduler-restart
2023-06-26 18:54:42,430 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:34613. Reason: scheduler-restart
2023-06-26 18:54:42,430 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,430 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:34885. Reason: scheduler-restart
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:35255. Reason: scheduler-restart
2023-06-26 18:54:42,431 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,431 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,431 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,431 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,431 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,431 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:36615. Reason: scheduler-restart
2023-06-26 18:54:42,432 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,432 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34257
2023-06-26 18:54:42,432 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,432 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:37443. Reason: scheduler-restart
2023-06-26 18:54:42,432 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,432 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,433 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,433 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,433 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:40815. Reason: scheduler-restart
2023-06-26 18:54:42,433 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,434 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,434 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,434 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,435 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,436 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,436 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,436 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:41499. Reason: scheduler-restart
2023-06-26 18:54:42,437 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,437 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:44743. Reason: scheduler-restart
2023-06-26 18:54:42,437 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:44785. Reason: scheduler-restart
2023-06-26 18:54:42,437 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,437 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,438 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,438 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,438 - distributed.nanny - INFO - Nanny asking worker to close. Reason: scheduler-restart
2023-06-26 18:54:42,438 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,438 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,438 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,438 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,438 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,440 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:45235. Reason: scheduler-restart
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,440 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,440 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,440 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:41585. Reason: scheduler-restart
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,440 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:44865. Reason: scheduler-restart
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,440 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,441 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,441 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,441 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,441 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:43879. Reason: scheduler-restart
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,441 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,442 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,442 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,442 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,442 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,442 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,442 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,442 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,443 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44785
2023-06-26 18:54:42,443 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40815
2023-06-26 18:54:42,443 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41499
2023-06-26 18:54:42,443 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44743
2023-06-26 18:54:42,443 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,443 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,444 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,445 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,446 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,446 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,446 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,446 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,447 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,447 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,447 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44785
2023-06-26 18:54:42,447 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,447 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40815
2023-06-26 18:54:42,447 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41499
2023-06-26 18:54:42,447 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44743
2023-06-26 18:54:42,451 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:46113. Reason: scheduler-restart
2023-06-26 18:54:42,451 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34613
2023-06-26 18:54:42,451 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34603
2023-06-26 18:54:42,451 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35255
2023-06-26 18:54:42,451 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34885
2023-06-26 18:54:42,451 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36615
2023-06-26 18:54:42,451 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37443
2023-06-26 18:54:42,452 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44785
2023-06-26 18:54:42,452 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40815
2023-06-26 18:54:42,452 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41499
2023-06-26 18:54:42,452 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44743
2023-06-26 18:54:42,453 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41585
2023-06-26 18:54:42,454 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43879
2023-06-26 18:54:42,455 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41585
2023-06-26 18:54:42,455 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,455 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43879
2023-06-26 18:54:42,455 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44865
2023-06-26 18:54:42,455 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,456 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,457 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,457 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44785
2023-06-26 18:54:42,458 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40815
2023-06-26 18:54:42,458 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41499
2023-06-26 18:54:42,458 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44743
2023-06-26 18:54:42,458 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41585
2023-06-26 18:54:42,458 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43879
2023-06-26 18:54:42,458 - distributed.core - INFO - Connection to tcp://10.120.104.11:8786 has been closed.
2023-06-26 18:54:42,461 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,463 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:42,472 - distributed.nanny - INFO - Worker closed
2023-06-26 18:54:44,162 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,105 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:48,105 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:48,110 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,111 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,135 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,138 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,139 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,141 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,145 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,146 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,148 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,151 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,154 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,157 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,159 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,162 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,167 - distributed.nanny - WARNING - Restarting worker
2023-06-26 18:54:48,275 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,551 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:39797
2023-06-26 18:54:49,552 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:39797
2023-06-26 18:54:49,552 - distributed.worker - INFO -          dashboard at:        10.120.104.11:33073
2023-06-26 18:54:49,552 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:49,552 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:49,552 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:49,552 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:49,552 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ct_kjs55
2023-06-26 18:54:49,553 - distributed.worker - INFO - Starting Worker plugin RMMSetup-cecf140a-4b3c-4411-8e06-5c345f94e400
2023-06-26 18:54:49,690 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33538912-d08d-4179-881c-c3feac6d969b
2023-06-26 18:54:49,691 - distributed.worker - INFO - Starting Worker plugin PreImport-c8c95d66-21d1-4ded-9a49-b7054fc346d7
2023-06-26 18:54:49,691 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:49,702 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:49,702 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:49,704 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:49,731 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,743 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,743 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,778 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,793 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,813 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,813 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,817 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,817 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,818 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,818 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,822 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,822 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,824 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,824 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,846 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,846 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,850 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,852 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,852 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:49,913 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,918 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,960 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,972 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,973 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,993 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,996 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,997 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:49,998 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-06-26 18:54:49,999 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-06-26 18:54:50,002 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:50,003 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:50,024 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:50,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:50,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:50,051 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:50,178 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-06-26 18:54:55,656 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:46081
2023-06-26 18:54:55,656 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:46081
2023-06-26 18:54:55,656 - distributed.worker - INFO -          dashboard at:        10.120.104.11:41873
2023-06-26 18:54:55,656 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,656 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,656 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,656 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,656 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uira43sk
2023-06-26 18:54:55,657 - distributed.worker - INFO - Starting Worker plugin PreImport-65f74977-436d-426d-af83-eee377a8e2dd
2023-06-26 18:54:55,657 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1e1c1ff3-fd2c-495b-9b66-e6f13528ba5b
2023-06-26 18:54:55,700 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:35295
2023-06-26 18:54:55,700 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:35295
2023-06-26 18:54:55,700 - distributed.worker - INFO -          dashboard at:        10.120.104.11:35179
2023-06-26 18:54:55,701 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,701 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,701 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,701 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,701 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cfqknlg8
2023-06-26 18:54:55,701 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ece8618-3287-4e52-a932-0800e42e4d2d
2023-06-26 18:54:55,704 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:38895
2023-06-26 18:54:55,704 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:38895
2023-06-26 18:54:55,705 - distributed.worker - INFO -          dashboard at:        10.120.104.11:45929
2023-06-26 18:54:55,705 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,704 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:41957
2023-06-26 18:54:55,705 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,705 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:41957
2023-06-26 18:54:55,705 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,705 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,705 - distributed.worker - INFO -          dashboard at:        10.120.104.11:35385
2023-06-26 18:54:55,705 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_2kcti5e
2023-06-26 18:54:55,705 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,705 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,705 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,705 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,705 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oni6vk44
2023-06-26 18:54:55,705 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d23e24e8-cad1-4bc4-9ee4-84ff20ebf606
2023-06-26 18:54:55,706 - distributed.worker - INFO - Starting Worker plugin PreImport-964e7f09-2db4-4af6-95d0-b25b95c1c66c
2023-06-26 18:54:55,706 - distributed.worker - INFO - Starting Worker plugin RMMSetup-044fa8fd-fd78-4ba7-bf30-4273b2c30406
2023-06-26 18:54:55,709 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:45169
2023-06-26 18:54:55,709 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:45169
2023-06-26 18:54:55,709 - distributed.worker - INFO -          dashboard at:        10.120.104.11:42787
2023-06-26 18:54:55,709 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,709 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,709 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,709 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,709 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ygain2mu
2023-06-26 18:54:55,710 - distributed.worker - INFO - Starting Worker plugin PreImport-1a531fc0-823d-44be-a618-cc81948c5867
2023-06-26 18:54:55,710 - distributed.worker - INFO - Starting Worker plugin RMMSetup-12d36cbd-5284-4b0b-9185-0f91ab836434
2023-06-26 18:54:55,731 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44555
2023-06-26 18:54:55,732 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44555
2023-06-26 18:54:55,732 - distributed.worker - INFO -          dashboard at:        10.120.104.11:35589
2023-06-26 18:54:55,732 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,732 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,732 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,732 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,732 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rqq40ypg
2023-06-26 18:54:55,733 - distributed.worker - INFO - Starting Worker plugin RMMSetup-78e95f79-ecb0-446e-8a49-6f8c124c07f0
2023-06-26 18:54:55,752 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:41281
2023-06-26 18:54:55,752 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:41281
2023-06-26 18:54:55,752 - distributed.worker - INFO -          dashboard at:        10.120.104.11:40819
2023-06-26 18:54:55,752 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,752 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,752 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,752 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,752 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pm6qqwr2
2023-06-26 18:54:55,753 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7e2c2580-af4c-4186-bf75-38e5199baa31
2023-06-26 18:54:55,820 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44001
2023-06-26 18:54:55,820 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44001
2023-06-26 18:54:55,820 - distributed.worker - INFO -          dashboard at:        10.120.104.11:39763
2023-06-26 18:54:55,820 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,820 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,820 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,820 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,820 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zktmh088
2023-06-26 18:54:55,821 - distributed.worker - INFO - Starting Worker plugin PreImport-3a300ce2-8477-43f5-9971-4988d5e35379
2023-06-26 18:54:55,821 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e0996716-a56f-4639-801b-9cbd6f75195f
2023-06-26 18:54:55,821 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:42911
2023-06-26 18:54:55,821 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:42911
2023-06-26 18:54:55,822 - distributed.worker - INFO -          dashboard at:        10.120.104.11:41101
2023-06-26 18:54:55,822 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,822 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,822 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,822 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,822 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wfotkd09
2023-06-26 18:54:55,822 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-71adcd00-02ba-42fc-8659-9b14b1d9ebab
2023-06-26 18:54:55,823 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aaa44c7f-0963-41c9-b924-52f683446a0a
2023-06-26 18:54:55,864 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44345
2023-06-26 18:54:55,864 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44345
2023-06-26 18:54:55,864 - distributed.worker - INFO -          dashboard at:        10.120.104.11:39359
2023-06-26 18:54:55,864 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,864 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,864 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,865 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,865 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n8h4snmm
2023-06-26 18:54:55,865 - distributed.worker - INFO - Starting Worker plugin PreImport-e8e26b9f-09b3-43e1-bbcd-cb8d8eed0567
2023-06-26 18:54:55,865 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ee749603-8d2e-4d45-9e27-67f5eb3c4ad7
2023-06-26 18:54:55,871 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:43249
2023-06-26 18:54:55,872 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:43249
2023-06-26 18:54:55,872 - distributed.worker - INFO -          dashboard at:        10.120.104.11:46365
2023-06-26 18:54:55,872 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,872 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,872 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,872 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,872 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mcdvs5ul
2023-06-26 18:54:55,872 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1ab9bd1d-3c31-4246-8341-824afcf05da0
2023-06-26 18:54:55,906 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:41683
2023-06-26 18:54:55,906 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:41683
2023-06-26 18:54:55,906 - distributed.worker - INFO -          dashboard at:        10.120.104.11:45277
2023-06-26 18:54:55,906 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,906 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,906 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,906 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,906 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d6d3c5zm
2023-06-26 18:54:55,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-10595ffc-e720-4fb5-8d5d-95468f5569fd
2023-06-26 18:54:55,917 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:45213
2023-06-26 18:54:55,917 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:45213
2023-06-26 18:54:55,917 - distributed.worker - INFO -          dashboard at:        10.120.104.11:42827
2023-06-26 18:54:55,917 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,917 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,917 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,917 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,917 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dy35zn4b
2023-06-26 18:54:55,918 - distributed.worker - INFO - Starting Worker plugin PreImport-a80e183f-2129-4b4d-88af-c3046a5ff407
2023-06-26 18:54:55,918 - distributed.worker - INFO - Starting Worker plugin RMMSetup-39b8238a-df01-40b6-88ab-e88304813000
2023-06-26 18:54:55,941 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:43681
2023-06-26 18:54:55,941 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:43681
2023-06-26 18:54:55,941 - distributed.worker - INFO -          dashboard at:        10.120.104.11:33297
2023-06-26 18:54:55,941 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,941 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,941 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,941 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,941 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v_sz_wmq
2023-06-26 18:54:55,942 - distributed.worker - INFO - Starting Worker plugin PreImport-44039f8b-8ceb-49a9-a78f-3396c293cbd2
2023-06-26 18:54:55,942 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9fe81131-74a4-42bc-a69a-867265bb5ed5
2023-06-26 18:54:55,949 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:37817
2023-06-26 18:54:55,949 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:37817
2023-06-26 18:54:55,949 - distributed.worker - INFO -          dashboard at:        10.120.104.11:33095
2023-06-26 18:54:55,949 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-06-26 18:54:55,949 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:55,949 - distributed.worker - INFO -               Threads:                          1
2023-06-26 18:54:55,949 - distributed.worker - INFO -                Memory:                  94.41 GiB
2023-06-26 18:54:55,949 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i1u8omje
2023-06-26 18:54:55,949 - distributed.worker - INFO - Starting Worker plugin PreImport-a7648c5e-6b72-44e1-a43d-a195aa0d7a8f
2023-06-26 18:54:55,950 - distributed.worker - INFO - Starting Worker plugin RMMSetup-50874f0d-4097-4f2b-a801-4afa066abef9
2023-06-26 18:54:56,180 - distributed.worker - INFO - Starting Worker plugin PreImport-27cec853-a3dd-4fb8-9598-183f3c3864c2
2023-06-26 18:54:56,181 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3bd25c2b-568d-45cb-91d0-12b74981ea6f
2023-06-26 18:54:56,181 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,192 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,192 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,196 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,261 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f622a4b2-303b-41be-a0a2-c8bfab20e46f
2023-06-26 18:54:56,261 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-608ad855-62be-4f7b-b1f1-81168fd994c0
2023-06-26 18:54:56,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fb9ddda8-59fb-4e0c-926b-6e908e488f66
2023-06-26 18:54:56,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2faae938-b37f-4439-8f1b-2d6f59bbbfc5
2023-06-26 18:54:56,262 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,262 - distributed.worker - INFO - Starting Worker plugin PreImport-94a1e63f-3df8-421b-9f78-c7495e3b07f3
2023-06-26 18:54:56,262 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,262 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-33a732cd-d3aa-436c-98b6-f198fb50ea0e
2023-06-26 18:54:56,263 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,263 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,263 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,272 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,272 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,274 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,274 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,275 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,275 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,276 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,279 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,280 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,333 - distributed.worker - INFO - Starting Worker plugin PreImport-1077e67b-c998-47cc-b586-b000621e8738
2023-06-26 18:54:56,333 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,333 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,334 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,334 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,334 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,336 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,342 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7e6ca723-6cf2-414f-b387-16a8749ec1c4
2023-06-26 18:54:56,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-79d994ed-a71a-427e-a5ba-c8e52b65dc29
2023-06-26 18:54:56,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2b4e5a3c-f52c-40eb-87f2-39ec65c217c2
2023-06-26 18:54:56,356 - distributed.worker - INFO - Starting Worker plugin PreImport-d99b79d7-d3e8-4bff-b87e-e6c0eb0e0f02
2023-06-26 18:54:56,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f662061a-0c38-452d-b574-563ea66061f7
2023-06-26 18:54:56,356 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,357 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,357 - distributed.worker - INFO - Starting Worker plugin PreImport-adb013d2-548f-40ac-b4ac-4f0f0c964c6e
2023-06-26 18:54:56,357 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5616bbf2-52d6-4c49-814a-225a00e57073
2023-06-26 18:54:56,357 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,357 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e2abe709-3e30-46da-afcb-9f53bd94be75
2023-06-26 18:54:56,357 - distributed.worker - INFO - Starting Worker plugin PreImport-a2c855d4-8b35-4cf0-b437-381fffc492a1
2023-06-26 18:54:56,357 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,358 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,358 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,358 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,358 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,366 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,367 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,367 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,367 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,367 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,368 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,368 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,369 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,369 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,370 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,372 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,372 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,372 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,375 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,375 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,376 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,376 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,381 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,383 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,404 - distributed.worker - INFO - Starting Worker plugin PreImport-367f200c-55e7-416e-aa61-ba02ee1a3f67
2023-06-26 18:54:56,404 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5a727567-bd3b-476c-b578-f9644f21e7a5
2023-06-26 18:54:56,404 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e2f0c58-5fb2-4f79-a9bf-78526a81fc48
2023-06-26 18:54:56,406 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,407 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,423 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,423 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,425 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-06-26 18:54:56,425 - distributed.worker - INFO - -------------------------------------------------
2023-06-26 18:54:56,430 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:54:56,433 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-06-26 18:55:05,798 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:05,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:05,848 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:05,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:05,893 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:05,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:05,943 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:05,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,075 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,115 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,190 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,300 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,334 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,373 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,444 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,449 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,522 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,532 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,721 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,761 - distributed.worker - INFO - Run out-of-band function 'enable_spilling'
2023-06-26 18:55:06,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,773 - distributed.worker - INFO - Run out-of-band function '_get_nvml_device_index'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
2023-06-26 18:55:06,783 - distributed.worker - INFO - Run out-of-band function '_func_ucp_listener_port'
[1687805706.784108] [exp01:402088:0]            sock.c:470  UCX  ERROR bind(fd=369 addr=0.0.0.0:57074) failed: Address already in use
2023-06-26 18:55:06,794 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,794 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,794 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,794 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,794 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:06,795 - distributed.worker - INFO - Run out-of-band function '_func_init_all'
2023-06-26 18:55:09,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:14,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:19,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:23,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:23,386 - distributed.worker - INFO - Run out-of-band function '_subcomm_init'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,108 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,109 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
2023-06-26 18:55:35,109 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'
