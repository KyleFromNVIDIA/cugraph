RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 16:45:02,055 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 16:45:02,572 - distributed.scheduler - INFO - State start
2023-06-26 16:45:02,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-l2ogquy_', purging
2023-06-26 16:45:02,573 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-1yunr2cw', purging
2023-06-26 16:45:02,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-jbsg6yvn', purging
2023-06-26 16:45:02,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-4ywpbt5j', purging
2023-06-26 16:45:02,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-fmp4o0v9', purging
2023-06-26 16:45:02,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-j3iyoj2_', purging
2023-06-26 16:45:02,574 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-gpn07q0p', purging
2023-06-26 16:45:02,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-xlrqamh3', purging
2023-06-26 16:45:02,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-xx8pvta7', purging
2023-06-26 16:45:02,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-p27eeyau', purging
2023-06-26 16:45:02,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-yxvjfl18', purging
2023-06-26 16:45:02,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-87vmepvi', purging
2023-06-26 16:45:02,575 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-43iy_ghz', purging
2023-06-26 16:45:02,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-c6pmx682', purging
2023-06-26 16:45:02,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-f33mkei9', purging
2023-06-26 16:45:02,576 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-p9f9d7kx', purging
2023-06-26 16:45:02,588 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 16:45:02,589 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 16:45:02,589 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 16:45:21,571 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39393', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,578 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39393
2023-06-26 16:45:21,578 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55660
2023-06-26 16:45:21,599 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33023', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,599 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33023
2023-06-26 16:45:21,599 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55672
2023-06-26 16:45:21,702 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39513', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,703 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39513
2023-06-26 16:45:21,703 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55688
2023-06-26 16:45:21,717 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37927', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,717 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37927
2023-06-26 16:45:21,717 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55704
2023-06-26 16:45:21,719 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38807', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,719 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38807
2023-06-26 16:45:21,719 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55708
2023-06-26 16:45:21,776 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41715', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,776 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41715
2023-06-26 16:45:21,776 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55720
2023-06-26 16:45:21,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35795', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,782 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35795
2023-06-26 16:45:21,782 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55730
2023-06-26 16:45:21,835 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40355', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,835 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40355
2023-06-26 16:45:21,835 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55746
2023-06-26 16:45:21,835 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33591', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,836 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33591
2023-06-26 16:45:21,836 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55744
2023-06-26 16:45:21,892 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41557', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,893 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41557
2023-06-26 16:45:21,893 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55754
2023-06-26 16:45:21,910 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38993', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,911 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38993
2023-06-26 16:45:21,911 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55756
2023-06-26 16:45:21,919 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35073', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,919 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35073
2023-06-26 16:45:21,919 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55772
2023-06-26 16:45:21,974 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41149', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,975 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41149
2023-06-26 16:45:21,975 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55784
2023-06-26 16:45:21,992 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41367', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,992 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41367
2023-06-26 16:45:21,992 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55798
2023-06-26 16:45:21,998 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33885', status: init, memory: 0, processing: 0>
2023-06-26 16:45:21,998 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33885
2023-06-26 16:45:21,998 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55794
2023-06-26 16:45:22,001 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41127', status: init, memory: 0, processing: 0>
2023-06-26 16:45:22,002 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41127
2023-06-26 16:45:22,002 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:55802
2023-06-26 16:45:30,478 - distributed.scheduler - INFO - Receive client connection: Client-dc7cab93-1440-11ee-b007-5cff35c1a711
2023-06-26 16:45:30,478 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37908
2023-06-26 16:45:31,199 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 16:46:22,779 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 16:46:36,227 - distributed.protocol.pickle - INFO - Failed to deserialize b'\x80\x05\x95\x9d`\x00\x00\x00\x00\x00\x00\x8c\x1edistributed.protocol.serialize\x94\x8c\x08ToPickle\x94\x93\x94)\x81\x94}\x94\x8c\x04data\x94\x8c\x13dask.highlevelgraph\x94\x8c\x0eHighLevelGraph\x94\x93\x94)\x81\x94}\x94(\x8c\x0cdependencies\x94}\x94(\x8c1__filter_batches-5e4b0443eac066eccbe24085cfe3a86f\x94\x8f\x94(\x8c\'rename-96e1e9fd787d6e520c376faa92d0825e\x94\x90h\x0f\x8f\x94u\x8c\x10key_dependencies\x94}\x94\x8c\x06layers\x94}\x94(h\r\x8c\x0edask.blockwise\x94\x8c\tBlockwise\x94\x93\x94)\x81\x94}\x94(\x8c\x0bannotations\x94N\x8c\x16collection_annotations\x94}\x94(\x8c\x0bnpartitions\x94K\x04\x8c\x07columns\x94]\x94(\x8c\x07_BATCH_\x94\x8c\x07_START_\x94e\x8c\x04type\x94\x8c\x18dask_cudf.core.DataFrame\x94\x8c\x0edataframe_type\x94\x8c\x1dcudf.core.dataframe.DataFrame\x94\x8c\rseries_dtypes\x94}\x94(h \x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i4\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94bh!h*\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03h.NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94buu\x8c\x06output\x94h\r\x8c\x0eoutput_indices\x94\x8c\x02.0\x94\x85\x94\x8c\routput_blocks\x94N\x8c\x03dsk\x94}\x94h\r(\x8c\ndask.utils\x94\x8c\x05apply\x94\x93\x94\x8c\x13dask.dataframe.core\x94\x8c\x11apply_and_enforce\x94\x93\x94]\x94(\x8c\x13__dask_blockwise__0\x94\x8c\x13__dask_blockwise__1\x94\x8c\x13__dask_blockwise__2\x94\x8c\x13__dask_blockwise__3\x94\x8c\x13__dask_blockwise__4\x94e\x8c\x08builtins\x94\x8c\x04dict\x94\x93\x94]\x94(]\x94(\x8c\x05_func\x94\x8c\x17cloudpickle.cloudpickle\x94\x8c\x0e_make_function\x94\x93\x94(hM\x8c\r_builtin_type\x94\x93\x94\x8c\x08CodeType\x94\x85\x94R\x94(K\x01K\x00K\x00K\x03K\x05J\x1f\x00\x00\x01C\x16\x88\x00|\x01i\x00|\x02\xa4\x01d\x01|\x00i\x01\xa4\x01\x8e\x01S\x00\x94N\x8c\x0epartition_info\x94\x86\x94)hV\x8c\x04args\x94\x8c\x06kwargs\x94\x87\x94\x8cJ/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/dataframe/core.py\x94\x8c\x04func\x94ME\x1bC\x02\x16\x01\x94\x8c\torig_func\x94\x85\x94)t\x94R\x94}\x94(\x8c\x0b__package__\x94\x8c\x0edask.dataframe\x94\x8c\x08__name__\x94h>\x8c\x08__file__\x94h[uNNhM\x8c\x10_make_empty_cell\x94\x93\x94)R\x94\x85\x94t\x94R\x94\x8c\x1ccloudpickle.cloudpickle_fast\x94\x8c\x12_function_setstate\x94\x93\x94hl}\x94}\x94(heh\\\x8c\x0c__qualname__\x94\x8c\x1cmap_partitions.<locals>.func\x94\x8c\x0f__annotations__\x94}\x94\x8c\x0e__kwdefaults__\x94N\x8c\x0c__defaults__\x94N\x8c\n__module__\x94h>\x8c\x07__doc__\x94N\x8c\x0b__closure__\x94hM\x8c\n_make_cell\x94\x93\x94hQ\x8c\nMethodType\x94\x85\x94R\x94hO(hT(K\x05K\x00K\x00K\x07K\x03KCC^|\x04d\x00u\x00s\nt\x00|\x01\x83\x01d\x01k\x02r\x0cd\x00S\x00|\x04d\x02k\x03r\x1dt\x01|\x04t\x02\x83\x02s\x1dt\x03|\x04\x83\x01\x01\x00t\x04d\x03\x83\x01\x82\x01|\x01|\x02\x19\x00|\x03k\x01}\x05|\x01j\x05|\x05\x19\x00}\x06|\x01|\x05\x0f\x00\x19\x00}\x01|\x06S\x00\x94(NK\x00\x8c\x02sg\x94\x8c\x1fInvalid value of partition_info\x94t\x94(\x8c\x03len\x94\x8c\nisinstance\x94\x8c\x04dict\x94\x8c\x05print\x94\x8c\nValueError\x94\x8c\x03loc\x94t\x94(\x8c\x04self\x94\x8c\x02df\x94\x8c\x0ebatch_col_name\x94\x8c\x0cmax_batch_id\x94hV\x8c\x01f\x94h4t\x94\x8c\\/opt/conda/envs/rapids/lib/python3.10/site-packages/cugraph/gnn/data_loading/bulk_sampler.py\x94\x8c\x10__filter_batches\x94M6\x01C\x12\x14\x08\x04\x01\x12\x01\x08\x01\x08\x01\x0c\x02\n\x01\n\x01\x04\x01\x94))t\x94R\x94}\x94(hc\x8c\x18cugraph.gnn.data_loading\x94he\x8c%cugraph.gnn.data_loading.bulk_sampler\x94hf\x8c\\/opt/conda/envs/rapids/lib/python3.10/site-packages/cugraph/gnn/data_loading/bulk_sampler.py\x94uNNNt\x94R\x94hoh\x9b}\x94}\x94(heh\x92hr\x8c*EXPERIMENTAL__BulkSampler.__filter_batches\x94ht}\x94(h\x8c\x8c\x13cudf.core.dataframe\x94\x8c\tDataFrame\x94\x93\x94h\x8dhG\x8c\x03str\x94\x93\x94h\x8ehG\x8c\x03int\x94\x93\x94hV\x8c\t_operator\x94\x8c\x07getitem\x94\x93\x94\x8c\x06typing\x94\x8c\x05Union\x94\x93\x94hIh\xa4hG\x8c\x04type\x94\x93\x94N\x85\x94R\x94\x87\x94\x86\x94R\x94\x8c\x06return\x94h\xa2uhvNhwN\x85\x94hxh\x98hyNhzN\x8c\x17_cloudpickle_submodules\x94]\x94\x8c\x0b__globals__\x94}\x94u\x86\x94\x86R0\x8c\x0b__mp_main__\x94\x8c\x0bBulkSampler\x94\x93\x94)\x81\x94}\x94(\x8c"_EXPERIMENTAL__BulkSampler__logger\x94\x8c\x07logging\x94\x8c\tgetLogger\x94\x93\x94h\x98\x85\x94R\x94\x8c&_EXPERIMENTAL__BulkSampler__batch_size\x94M\x00\x02\x8c\'_EXPERIMENTAL__BulkSampler__output_path\x94\x8c6/tmp/ramdisk/ogbn_papers100M[4]_b512_f[10, 25]/samples\x94\x8c!_EXPERIMENTAL__BulkSampler__graph\x94\x8c\x1fcugraph.structure.graph_classes\x94\x8c\nMultiGraph\x94\x93\x94)\x81\x94}\x94(\x8c\x05_Impl\x94\x8c=cugraph.structure.graph_implementation.simpleDistributedGraph\x94\x8c\x1asimpleDistributedGraphImpl\x94\x93\x94)\x81\x94}\x94(\x8c\x08edgelist\x94h\xd0\x8c#simpleDistributedGraphImpl.EdgeList\x94\x93\x94)\x81\x94}\x94(\x8c\x0bedgelist_df\x94\x8c\x0edask_cudf.core\x94h\xa1\x93\x94)\x81\x94(h\x08)\x81\x94}\x94(h\x0b}\x94(\x8c\'assign-9eb0393f33fd3955382618d83f6c59bf\x94\x8f\x94(\x8c\'rename-f397035708136a3f38dc9613aa349ae9\x94\x8c(getitem-7b49bb8e33def13dff9c3898cbf97a17\x94\x90\x8c\'assign-79e7b6b9955aff4f05b61c6a13c74862\x94\x8f\x94(\x8c\'assign-7a31f8143cc223f15cd3762c9b451864\x94\x8c$add-bd81a73d3da345912094025794950413\x94\x90h\xe7\x8f\x94(\x8c$add-2b5167922093b28b8b69868e84a15525\x94\x8c-read-parquet-1a83665a6299205a0cf4e9c5910a7701\x94\x90h\xeb\x8f\x94\x8c(getitem-36ffef13e0cce494c224877403ba899d\x94\x8f\x94(h\xeb\x90h\xea\x8f\x94(h\xed\x90\x8c(getitem-0f5db0edc6a99e5906eedb06c6888b74\x94\x8f\x94(h\xe7\x90h\xe8\x8f\x94(h\xf0\x90\x8c._replicate_df-4bbe7483c6fcc384eeb388e90889fd63\x94\x8f\x94(h\xe5\x90\x8c(getitem-d623c2a08afc56c7c9d8ad04e3357704\x94\x8f\x94(h\xf3\x90\x8c(getitem-fab82f4b59ed72d3a0f98011920f393a\x94\x8f\x94(h\xf5\x90\x8c)to_frame-45be7c687423dda9a22aceb1cbac07a5\x94\x8f\x94(h\xf7\x90h\xe3\x8f\x94(h\xf9\x90h\xe4\x8f\x94(h\xf5\x90uh\x11}\x94h\x13}\x94(h\xe1h\x17)\x81\x94}\x94(h\x1aNh\x1b}\x94(h\x1dK h\x1e]\x94(\x8c\x03src\x94\x8c\x03dst\x94eh"\x8c\x18dask_cudf.core.DataFrame\x94h$\x8c\x1dcudf.core.dataframe.DataFrame\x94h&}\x94(j\x03\x01\x00\x00h2j\x04\x01\x00\x00h2uuh4h\xe1h5\x8c\x02.0\x94\x85\x94h8Nh9}\x94h\xe1(\x8c\x16dask.dataframe.methods\x94\x8c\x06assign\x94\x93\x94\x8c\x13__dask_blockwise__0\x94\x8c\x13__dask_blockwise__1\x94\x8c\x13__dask_blockwise__2\x94t\x94s\x8c\tnumblocks\x94}\x94(h\xe3K \x85\x94h\xe4K \x85\x94u\x8c\x07io_deps\x94}\x94\x8c\x07indices\x94h\xe3j\x08\x01\x00\x00\x85\x94\x86\x94j\x04\x01\x00\x00N\x86\x94h\xe4j\x08\x01\x00\x00\x85\x94\x86\x94\x87\x94\x8c\x0bconcatenate\x94N\x8c\x08new_axes\x94}\x94ubh\xe5h\x17)\x81\x94}\x94(h\x1aNh\x1b}\x94(h\x1dK h\x1e]\x94(\x8c\x03src\x94\x8c\x03dst\x94eh"\x8c\x18dask_cudf.core.DataFrame\x94h$\x8c\x1dcudf.core.dataframe.DataFrame\x94h&}\x94(j&\x01\x00\x00h2j\'\x01\x00\x00h2uuh4h\xe5h5\x8c\x02.0\x94\x85\x94h8Nh9}\x94h\xe5(j\r\x01\x00\x00\x8c\x13__dask_blockwise__0\x94\x8c\x13__dask_blockwise__1\x94\x8c\x13__dask_blockwise__2\x94t\x94sj\x12\x01\x00\x00}\x94(h\xe7K \x85\x94h\xe8K \x85\x94uj\x16\x01\x00\x00}\x94j\x18\x01\x00\x00h\xe7j+\x01\x00\x00\x85\x94\x86\x94j\x04\x01\x00\x00N\x86\x94h\xe8j+\x01\x00\x00\x85\x94\x86\x94\x87\x94j\x1f\x01\x00\x00Nj \x01\x00\x00}\x94ubh\xe7h\x17)\x81\x94}\x94(h\x1aNh\x1b}\x94(h\x1dK h\x1e]\x94(j&\x01\x00\x00j\'\x01\x00\x00eh"\x8c\x18dask_cudf.core.DataFrame\x94h$\x8c\x1dcudf.core.dataframe.DataFrame\x94h&}\x94(j&\x01\x00\x00h2j\'\x01\x00\x00h2uuh4h\xe7h5\x8c\x02.0\x94\x85\x94h8Nh9}\x94h\xe7(j\r\x01\x00\x00\x8c\x13__dask_blockwise__0\x94\x8c\x13__dask_blockwise__1\x94\x8c\x13__dask_blockwise__2\x94t\x94sj\x12\x01\x00\x00}\x94(h\xebK \x85\x94h\xeaK \x85\x94uj\x16\x01\x00\x00}\x94j\x18\x01\x00\x00h\xebjD\x01\x00\x00\x85\x94\x86\x94j\x03\x01\x00\x00N\x86\x94h\xeajD\x01\x00\x00\x85\x94\x86\x94\x87\x94j\x1f\x01\x00\x00Nj \x01\x00\x00}\x94ubh\xeb\x8c\x0bdask.layers\x94\x8c\x10DataFrameIOLayer\x94\x93\x94)\x81\x94}\x94(\x8c\x04name\x94h\xeb\x8c\x08_columns\x94]\x94(j&\x01\x00\x00j\'\x01\x00\x00e\x8c\x06inputs\x94]\x94(]\x94}\x94\x8c\x05piece\x94\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/0.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/1.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/2.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/3.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/4.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/5.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/6.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/7.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/8.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8cZ/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/9.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/10.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/11.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/12.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/13.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/14.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/15.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/16.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/17.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/18.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/19.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/20.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/21.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/22.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/23.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/24.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/25.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/26.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/27.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/28.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/29.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/30.parquet\x94]\x94K\x00a]\x94\x87\x94sa]\x94}\x94jb\x01\x00\x00\x8c[/datasets/abarghi/ogbn_papers100M/parquet/paper__cites__paper/edge_index.parquet/31.parquet\x94]\x94K\x00a]\x94\x87\x94sae\x8c\x07io_func\x94\x8c\x1edask.dataframe.io.parquet.core\x94\x8c\x16ParquetFunctionWrapper\x94\x93\x94)\x81\x94}\x94(\x8c\x06engine\x94\x8c\x14dask_cudf.io.parquet\x94\x8c\nCudfEngine\x94\x93\x94\x8c\x02fs\x94\x8c\x0bfsspec.spec\x94\x8c\rmake_instance\x94\x93\x94\x8c\x1cfsspec.implementations.local\x94\x8c\x0fLocalFileSystem\x94\x93\x94)}\x94\x87\x94R\x94\x8c\x04meta\x94h\x7fhO(hT(K\x03K\x00K\x00K\x04K\x06KCC.d\x01d\x02\x84\x00t\x00|\x01d\x03\x19\x00t\x01t\x02|\x02\x83\x02\x83\x02D\x00\x83\x01}\x02|\x00\xa0\x03|\x01|\x02\xa1\x02}\x03|\x03S\x00\x94(X\x04\x02\x00\x00Perform device-side deserialization tasks.\n\n        Parameters\n        ----------\n        header : dict\n            The metadata required to reconstruct the object.\n        frames : list\n            The Buffers or memoryviews that the object should contain.\n\n        Returns\n        -------\n        Serializable\n            A new instance of `cls` (a subclass of `Serializable`) equivalent\n            to the instance that was serialized to produce the header and\n            frames.\n\n        :meta private:\n        \x94hT(K\x01K\x00K\x00K\x03K\x05KSC&g\x00|\x00]\x0f\\\x02}\x01}\x02|\x01r\x0ft\x00j\x01j\x02\xa0\x03|\x02\xa1\x01n\x01|\x02\x91\x02q\x02S\x00\x94)(\x8c\x04cudf\x94\x8c\x04core\x94\x8c\x06buffer\x94\x8c\tas_buffer\x94t\x94\x8c\x02.0\x94\x8c\x01c\x94h\x8f\x87\x94\x8cD/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/abc.py\x94\x8c\n<listcomp>\x94K\xacC\x08\x06\x00\x06\x02\x14\xff\x06\xff\x94))t\x94R\x94\x8c1Serializable.host_deserialize.<locals>.<listcomp>\x94\x8c\x07is-cuda\x94t\x94(\x8c\x03zip\x94\x8c\x03map\x94\x8c\nmemoryview\x94\x8c\x12device_deserialize\x94t\x94(\x8c\x03cls\x94\x8c\x06header\x94\x8c\x06frames\x94\x8c\x03obj\x94t\x94jA\x02\x00\x00\x8c\x10host_deserialize\x94K\x98C\n\x06\x14\x12\x02\x06\xfe\x0c\x04\x04\x01\x94))t\x94R\x94}\x94(hc\x8c\tcudf.core\x94he\x8c\rcudf.core.abc\x94hfjA\x02\x00\x00uNNNt\x94R\x94hoj[\x02\x00\x00}\x94}\x94(hejS\x02\x00\x00hr\x8c\x1dSerializable.host_deserialize\x94ht}\x94hvNhwNhxjY\x02\x00\x00hyj7\x02\x00\x00hzNh\xb6]\x94h\xb8}\x94j9\x02\x00\x00hM\x8c\tsubimport\x94\x93\x94j9\x02\x00\x00\x85\x94R\x94su\x86\x94\x86R0h\xa2\x86\x94R\x94}\x94(\x8c\x0ftype-serialized\x94C0\x80\x04\x95%\x00\x00\x00\x00\x00\x00\x00\x8c\x13cudf.core.dataframe\x94\x8c\tDataFrame\x94\x93\x94.\x94\x8c\x0ccolumn_names\x94C\x1a\x80\x04\x95\x0f\x00\x00\x00\x00\x00\x00\x00\x8c\x03src\x94\x8c\x03dst\x94\x86\x94.\x94h\x1e}\x94(\x8c\x0ftype-serialized\x94C=\x80\x04\x952\x00\x00\x00\x00\x00\x00\x00\x8c\x1acudf.core.column.numerical\x94\x8c\x0fNumericalColumn\x94\x93\x94.\x94h)CB\x80\x04\x957\x00\x00\x00\x00\x00\x00\x00\x8c\x05numpy\x94\x8c\x05dtype\x94\x93\x94\x8c\x02i8\x94\x89\x88\x87\x94R\x94(K\x03\x8c\x01<\x94NNNJ\xff\xff\xff\xffJ\xff\xff\xff\xffK\x00t\x94b.\x94\x8c\x18dtype-is-cudf-'
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/protocol/pickle.py", line 94, in loads
    return pickle.loads(x, buffers=buffers)
AttributeError: Can't get attribute 'BulkSampler' on <module '__main__' from '/opt/conda/envs/rapids/bin/dask-scheduler'>
2023-06-26 16:46:40,752 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 16:46:40,754 - distributed.scheduler - INFO - Restarting workers and releasing all keys.
2023-06-26 16:46:40,776 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55672; closing.
2023-06-26 16:46:40,776 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33023', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,777 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33023
2023-06-26 16:46:40,778 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55744; closing.
2023-06-26 16:46:40,778 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33591', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,778 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33591
2023-06-26 16:46:40,779 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55794; closing.
2023-06-26 16:46:40,779 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55772; closing.
2023-06-26 16:46:40,779 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55730; closing.
2023-06-26 16:46:40,779 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33885', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,779 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33885
2023-06-26 16:46:40,780 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35073', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,780 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35073
2023-06-26 16:46:40,780 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35795', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,780 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35795
2023-06-26 16:46:40,780 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55708; closing.
2023-06-26 16:46:40,781 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38807', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,781 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38807
2023-06-26 16:46:40,781 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55704; closing.
2023-06-26 16:46:40,781 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55756; closing.
2023-06-26 16:46:40,781 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37927', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,781 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37927
2023-06-26 16:46:40,782 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38993', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,782 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38993
2023-06-26 16:46:40,782 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55660; closing.
2023-06-26 16:46:40,782 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55688; closing.
2023-06-26 16:46:40,782 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39393', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,782 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39393
2023-06-26 16:46:40,783 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39513', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,783 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39513
2023-06-26 16:46:40,783 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55746; closing.
2023-06-26 16:46:40,784 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40355', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,784 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40355
2023-06-26 16:46:40,784 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:55746>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:46:40,789 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55802; closing.
2023-06-26 16:46:40,789 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41127', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,789 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41127
2023-06-26 16:46:40,790 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:55802>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:46:40,792 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55784; closing.
2023-06-26 16:46:40,792 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41149', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,792 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41149
2023-06-26 16:46:40,804 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55720; closing.
2023-06-26 16:46:40,804 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41715', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,804 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41715
2023-06-26 16:46:40,805 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55798; closing.
2023-06-26 16:46:40,805 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41367', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,805 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41367
2023-06-26 16:46:40,815 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:55754; closing.
2023-06-26 16:46:40,815 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41557', status: closing, memory: 0, processing: 0>
2023-06-26 16:46:40,815 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41557
2023-06-26 16:46:40,815 - distributed.scheduler - INFO - Lost all workers
2023-06-26 16:46:53,297 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45717', status: init, memory: 0, processing: 0>
2023-06-26 16:46:53,298 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45717
2023-06-26 16:46:53,298 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40708
2023-06-26 16:46:54,163 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39031', status: init, memory: 0, processing: 0>
2023-06-26 16:46:54,164 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39031
2023-06-26 16:46:54,164 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40718
2023-06-26 16:46:54,364 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40919', status: init, memory: 0, processing: 0>
2023-06-26 16:46:54,364 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40919
2023-06-26 16:46:54,364 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40750
2023-06-26 16:46:54,408 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40755', status: init, memory: 0, processing: 0>
2023-06-26 16:46:54,409 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40755
2023-06-26 16:46:54,409 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40758
2023-06-26 16:46:54,491 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41427', status: init, memory: 0, processing: 0>
2023-06-26 16:46:54,492 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41427
2023-06-26 16:46:54,492 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40772
2023-06-26 16:46:54,597 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34105', status: init, memory: 0, processing: 0>
2023-06-26 16:46:54,598 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34105
2023-06-26 16:46:54,598 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40782
2023-06-26 16:47:00,423 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39533', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,423 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39533
2023-06-26 16:47:00,423 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34592
2023-06-26 16:47:00,446 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39975', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,446 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39975
2023-06-26 16:47:00,446 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34602
2023-06-26 16:47:00,456 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:32799', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,456 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:32799
2023-06-26 16:47:00,457 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34606
2023-06-26 16:47:00,476 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33795', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,476 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33795
2023-06-26 16:47:00,476 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34618
2023-06-26 16:47:00,491 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44191', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,491 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44191
2023-06-26 16:47:00,491 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34640
2023-06-26 16:47:00,495 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42767', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,496 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42767
2023-06-26 16:47:00,496 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34624
2023-06-26 16:47:00,530 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44053', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,530 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44053
2023-06-26 16:47:00,530 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34648
2023-06-26 16:47:00,544 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:32837', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,545 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:32837
2023-06-26 16:47:00,545 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34662
2023-06-26 16:47:00,546 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39883', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,546 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39883
2023-06-26 16:47:00,546 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34678
2023-06-26 16:47:00,562 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33183', status: init, memory: 0, processing: 0>
2023-06-26 16:47:00,563 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33183
2023-06-26 16:47:00,563 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:34682
2023-06-26 16:47:00,624 - distributed.scheduler - INFO - Restarting finished.
2023-06-26 16:47:10,585 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 16:47:36,274 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 16:47:36,275 - distributed.scheduler - INFO - Remove client Client-dc7cab93-1440-11ee-b007-5cff35c1a711
2023-06-26 16:47:36,276 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37908; closing.
2023-06-26 16:47:36,276 - distributed.scheduler - INFO - Remove client Client-dc7cab93-1440-11ee-b007-5cff35c1a711
2023-06-26 16:47:36,276 - distributed.scheduler - INFO - Close client connection: Client-dc7cab93-1440-11ee-b007-5cff35c1a711
2023-06-26 16:49:46,064 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 16:49:46,064 - distributed.core - INFO - Connection to tcp://10.120.104.11:34648 has been closed.
2023-06-26 16:49:46,064 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44053', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,065 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44053
2023-06-26 16:49:46,065 - distributed.core - INFO - Connection to tcp://10.120.104.11:34682 has been closed.
2023-06-26 16:49:46,065 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33183', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,065 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33183
2023-06-26 16:49:46,066 - distributed.core - INFO - Connection to tcp://10.120.104.11:34662 has been closed.
2023-06-26 16:49:46,066 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:32837', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,067 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:32837
2023-06-26 16:49:46,067 - distributed.core - INFO - Connection to tcp://10.120.104.11:34606 has been closed.
2023-06-26 16:49:46,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:32799', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,067 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:32799
2023-06-26 16:49:46,067 - distributed.core - INFO - Connection to tcp://10.120.104.11:34618 has been closed.
2023-06-26 16:49:46,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33795', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,067 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33795
2023-06-26 16:49:46,067 - distributed.core - INFO - Connection to tcp://10.120.104.11:34602 has been closed.
2023-06-26 16:49:46,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39975', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,067 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39975
2023-06-26 16:49:46,067 - distributed.core - INFO - Connection to tcp://10.120.104.11:34640 has been closed.
2023-06-26 16:49:46,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44191', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44191
2023-06-26 16:49:46,068 - distributed.core - INFO - Connection to tcp://10.120.104.11:34624 has been closed.
2023-06-26 16:49:46,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42767', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42767
2023-06-26 16:49:46,068 - distributed.core - INFO - Connection to tcp://10.120.104.11:34678 has been closed.
2023-06-26 16:49:46,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39883', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39883
2023-06-26 16:49:46,069 - distributed.core - INFO - Connection to tcp://10.120.104.11:34592 has been closed.
2023-06-26 16:49:46,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39533', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,069 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39533
2023-06-26 16:49:46,069 - distributed.core - INFO - Connection to tcp://10.120.104.11:40708 has been closed.
2023-06-26 16:49:46,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45717', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,069 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45717
2023-06-26 16:49:46,070 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 16:49:46,071 - distributed.core - INFO - Connection to tcp://10.120.104.11:40772 has been closed.
2023-06-26 16:49:46,071 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41427', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,071 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41427
2023-06-26 16:49:46,071 - distributed.core - INFO - Connection to tcp://10.120.104.11:40718 has been closed.
2023-06-26 16:49:46,071 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39031', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,071 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39031
2023-06-26 16:49:46,072 - distributed.core - INFO - Connection to tcp://10.120.104.11:40750 has been closed.
2023-06-26 16:49:46,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40919', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,072 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40919
2023-06-26 16:49:46,072 - distributed.core - INFO - Connection to tcp://10.120.104.11:40782 has been closed.
2023-06-26 16:49:46,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34105', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,072 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34105
2023-06-26 16:49:46,072 - distributed.core - INFO - Connection to tcp://10.120.104.11:40758 has been closed.
2023-06-26 16:49:46,073 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40755', status: running, memory: 0, processing: 0>
2023-06-26 16:49:46,073 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40755
2023-06-26 16:49:46,073 - distributed.scheduler - INFO - Lost all workers
2023-06-26 16:49:46,073 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34606>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,073 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34662>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,073 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34618>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40782>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40782>: Stream is closed
2023-06-26 16:49:46,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40718>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40718>: Stream is closed
2023-06-26 16:49:46,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34592>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34678>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34602>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40758>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40758>: Stream is closed
2023-06-26 16:49:46,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40750>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40750>: Stream is closed
2023-06-26 16:49:46,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40772>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40772>: Stream is closed
2023-06-26 16:49:46,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34624>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:34640>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,076 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40708>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 16:49:46,077 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 16:49:46,081 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 16:49:46,081 - distributed.scheduler - INFO - End scheduler
