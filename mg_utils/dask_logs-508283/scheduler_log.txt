RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 20:46:27,154 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:46:27,672 - distributed.scheduler - INFO - State start
2023-06-26 20:46:27,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-0dm485e4', purging
2023-06-26 20:46:27,673 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3mfw94fi', purging
2023-06-26 20:46:27,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-5f8iu2gq', purging
2023-06-26 20:46:27,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-9goer3sb', purging
2023-06-26 20:46:27,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-cwmvfgvj', purging
2023-06-26 20:46:27,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-c3t59m1p', purging
2023-06-26 20:46:27,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-6ag2poqy', purging
2023-06-26 20:46:27,674 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-e5t0wzq0', purging
2023-06-26 20:46:27,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-wmzk2yic', purging
2023-06-26 20:46:27,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-dstldu4w', purging
2023-06-26 20:46:27,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-igjdfwde', purging
2023-06-26 20:46:27,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3af2g0ib', purging
2023-06-26 20:46:27,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-6_qcszx_', purging
2023-06-26 20:46:27,675 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-iexb9a_p', purging
2023-06-26 20:46:27,676 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-1y5lxc1b', purging
2023-06-26 20:46:27,676 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-59ymt6yl', purging
2023-06-26 20:46:27,688 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:46:27,688 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 20:46:27,689 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 20:46:46,527 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33029', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,530 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33029
2023-06-26 20:46:46,530 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60128
2023-06-26 20:46:46,538 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34927', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,539 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34927
2023-06-26 20:46:46,539 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60138
2023-06-26 20:46:46,539 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38647', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,540 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38647
2023-06-26 20:46:46,540 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60144
2023-06-26 20:46:46,546 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34589', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,547 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34589
2023-06-26 20:46:46,547 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60152
2023-06-26 20:46:46,599 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46549', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,599 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46549
2023-06-26 20:46:46,599 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60162
2023-06-26 20:46:46,607 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40733', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,608 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40733
2023-06-26 20:46:46,608 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60176
2023-06-26 20:46:46,654 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34383', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,654 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34383
2023-06-26 20:46:46,654 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60182
2023-06-26 20:46:46,694 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38349', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,695 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38349
2023-06-26 20:46:46,695 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60186
2023-06-26 20:46:46,722 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39355', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,722 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39355
2023-06-26 20:46:46,723 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60208
2023-06-26 20:46:46,730 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35527', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,730 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35527
2023-06-26 20:46:46,730 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60194
2023-06-26 20:46:46,759 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35141', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,759 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35141
2023-06-26 20:46:46,759 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60216
2023-06-26 20:46:46,769 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40785', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,770 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40785
2023-06-26 20:46:46,770 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60232
2023-06-26 20:46:46,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35367', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,783 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35367
2023-06-26 20:46:46,783 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60248
2023-06-26 20:46:46,787 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34909', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,787 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34909
2023-06-26 20:46:46,787 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60236
2023-06-26 20:46:46,796 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:32871', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,796 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:32871
2023-06-26 20:46:46,796 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60278
2023-06-26 20:46:46,799 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:36477', status: init, memory: 0, processing: 0>
2023-06-26 20:46:46,799 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:36477
2023-06-26 20:46:46,799 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:60262
2023-06-26 20:46:49,241 - distributed.scheduler - INFO - Receive client connection: Client-92808b8b-1462-11ee-8229-5cff35c1a711
2023-06-26 20:46:49,241 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:38100
2023-06-26 20:46:49,948 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 20:47:41,763 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 20:48:15,132 - distributed.scheduler - INFO - Remove client Client-92808b8b-1462-11ee-8229-5cff35c1a711
2023-06-26 20:48:15,187 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:38100; closing.
2023-06-26 20:48:15,188 - distributed.scheduler - INFO - Remove client Client-92808b8b-1462-11ee-8229-5cff35c1a711
2023-06-26 20:48:15,191 - distributed.scheduler - INFO - Close client connection: Client-92808b8b-1462-11ee-8229-5cff35c1a711
2023-06-26 20:49:26,861 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 20:49:26,862 - distributed.core - INFO - Connection to tcp://10.120.104.11:60278 has been closed.
2023-06-26 20:49:26,862 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:32871', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,862 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:32871
2023-06-26 20:49:26,863 - distributed.core - INFO - Connection to tcp://10.120.104.11:60182 has been closed.
2023-06-26 20:49:26,863 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34383', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,863 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34383
2023-06-26 20:49:26,863 - distributed.core - INFO - Connection to tcp://10.120.104.11:60152 has been closed.
2023-06-26 20:49:26,863 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34589', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,864 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34589
2023-06-26 20:49:26,864 - distributed.core - INFO - Connection to tcp://10.120.104.11:60128 has been closed.
2023-06-26 20:49:26,864 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33029', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,864 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33029
2023-06-26 20:49:26,864 - distributed.core - INFO - Connection to tcp://10.120.104.11:60194 has been closed.
2023-06-26 20:49:26,864 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35527', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,864 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35527
2023-06-26 20:49:26,865 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 20:49:26,866 - distributed.core - INFO - Connection to tcp://10.120.104.11:60232 has been closed.
2023-06-26 20:49:26,866 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40785', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,866 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40785
2023-06-26 20:49:26,866 - distributed.core - INFO - Connection to tcp://10.120.104.11:60186 has been closed.
2023-06-26 20:49:26,866 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38349', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,866 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38349
2023-06-26 20:49:26,866 - distributed.core - INFO - Connection to tcp://10.120.104.11:60236 has been closed.
2023-06-26 20:49:26,867 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34909', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,867 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34909
2023-06-26 20:49:26,867 - distributed.core - INFO - Connection to tcp://10.120.104.11:60262 has been closed.
2023-06-26 20:49:26,867 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:36477', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,867 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36477
2023-06-26 20:49:26,867 - distributed.core - INFO - Connection to tcp://10.120.104.11:60162 has been closed.
2023-06-26 20:49:26,867 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46549', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,867 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46549
2023-06-26 20:49:26,867 - distributed.core - INFO - Connection to tcp://10.120.104.11:60144 has been closed.
2023-06-26 20:49:26,867 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38647', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,867 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38647
2023-06-26 20:49:26,868 - distributed.core - INFO - Connection to tcp://10.120.104.11:60138 has been closed.
2023-06-26 20:49:26,868 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34927', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,868 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34927
2023-06-26 20:49:26,868 - distributed.core - INFO - Connection to tcp://10.120.104.11:60208 has been closed.
2023-06-26 20:49:26,868 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39355', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,868 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39355
2023-06-26 20:49:26,868 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60128>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:49:26,869 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60182>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:49:26,869 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60152>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:49:26,869 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60236>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60236>: Stream is closed
2023-06-26 20:49:26,869 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60138>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60138>: Stream is closed
2023-06-26 20:49:26,869 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60194>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:49:26,870 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60262>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60262>: Stream is closed
2023-06-26 20:49:26,870 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60186>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60186>: Stream is closed
2023-06-26 20:49:26,870 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60144>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60144>: Stream is closed
2023-06-26 20:49:26,870 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60208>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60208>: Stream is closed
2023-06-26 20:49:26,870 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60232>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60232>: Stream is closed
2023-06-26 20:49:26,870 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60162>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:60162>: Stream is closed
2023-06-26 20:49:26,871 - distributed.core - INFO - Connection to tcp://10.120.104.11:60176 has been closed.
2023-06-26 20:49:26,871 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40733', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,871 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40733
2023-06-26 20:49:26,871 - distributed.core - INFO - Connection to tcp://10.120.104.11:60216 has been closed.
2023-06-26 20:49:26,871 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35141', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,871 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35141
2023-06-26 20:49:26,871 - distributed.core - INFO - Connection to tcp://10.120.104.11:60248 has been closed.
2023-06-26 20:49:26,871 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35367', status: running, memory: 0, processing: 0>
2023-06-26 20:49:26,871 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35367
2023-06-26 20:49:26,872 - distributed.scheduler - INFO - Lost all workers
2023-06-26 20:49:26,872 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 20:49:26,874 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 20:49:26,875 - distributed.scheduler - INFO - End scheduler
