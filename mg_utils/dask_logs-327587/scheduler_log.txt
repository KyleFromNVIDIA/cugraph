RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 17:39:46,907 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 17:39:47,425 - distributed.scheduler - INFO - State start
2023-06-26 17:39:47,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-cd0y00eo', purging
2023-06-26 17:39:47,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-6nb_xn20', purging
2023-06-26 17:39:47,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-n8xa86tp', purging
2023-06-26 17:39:47,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-zy6vhmyt', purging
2023-06-26 17:39:47,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-jxj6nnll', purging
2023-06-26 17:39:47,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-382pqooq', purging
2023-06-26 17:39:47,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-qoz7em35', purging
2023-06-26 17:39:47,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-2dtix0kg', purging
2023-06-26 17:39:47,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-x2t6r8cv', purging
2023-06-26 17:39:47,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ep485ndl', purging
2023-06-26 17:39:47,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-b8v2ivh8', purging
2023-06-26 17:39:47,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-usgwiu1k', purging
2023-06-26 17:39:47,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-zmnqdj4r', purging
2023-06-26 17:39:47,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ktczt1j9', purging
2023-06-26 17:39:47,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-rcrzxbol', purging
2023-06-26 17:39:47,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-xpcg5uzu', purging
2023-06-26 17:39:47,441 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 17:39:47,442 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 17:39:47,442 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 17:40:01,147 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41311', status: init, memory: 0, processing: 0>
2023-06-26 17:40:01,151 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41311
2023-06-26 17:40:01,151 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36968
2023-06-26 17:40:03,838 - distributed.scheduler - INFO - Receive client connection: Client-7b8fa414-1448-11ee-8025-5cff35c1a711
2023-06-26 17:40:03,838 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36978
2023-06-26 17:40:05,352 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 17:40:05,376 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42241', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,377 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42241
2023-06-26 17:40:05,377 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37004
2023-06-26 17:40:05,655 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46755', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,655 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46755
2023-06-26 17:40:05,656 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37006
2023-06-26 17:40:05,841 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34335', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,842 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34335
2023-06-26 17:40:05,842 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37018
2023-06-26 17:40:05,889 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41223', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,889 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41223
2023-06-26 17:40:05,889 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37024
2023-06-26 17:40:05,897 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39527', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,897 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39527
2023-06-26 17:40:05,897 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37036
2023-06-26 17:40:05,948 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40729', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,949 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40729
2023-06-26 17:40:05,949 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37044
2023-06-26 17:40:05,962 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39707', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,962 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39707
2023-06-26 17:40:05,962 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37054
2023-06-26 17:40:05,975 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40029', status: init, memory: 0, processing: 0>
2023-06-26 17:40:05,975 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40029
2023-06-26 17:40:05,975 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37068
2023-06-26 17:40:06,002 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37485', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,002 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37485
2023-06-26 17:40:06,003 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37084
2023-06-26 17:40:06,012 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38969', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,013 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38969
2023-06-26 17:40:06,013 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37102
2023-06-26 17:40:06,013 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44405', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,013 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44405
2023-06-26 17:40:06,013 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37092
2023-06-26 17:40:06,029 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35841', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,029 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35841
2023-06-26 17:40:06,029 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37124
2023-06-26 17:40:06,036 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39363', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,036 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39363
2023-06-26 17:40:06,036 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37110
2023-06-26 17:40:06,044 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41725', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,045 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41725
2023-06-26 17:40:06,045 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37136
2023-06-26 17:40:06,048 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37359', status: init, memory: 0, processing: 0>
2023-06-26 17:40:06,049 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37359
2023-06-26 17:40:06,049 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:37144
2023-06-26 17:40:06,158 - distributed.scheduler - INFO - Remove client Client-7b8fa414-1448-11ee-8025-5cff35c1a711
2023-06-26 17:40:06,158 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36978; closing.
2023-06-26 17:40:06,158 - distributed.scheduler - INFO - Remove client Client-7b8fa414-1448-11ee-8025-5cff35c1a711
2023-06-26 17:40:06,158 - distributed.scheduler - INFO - Close client connection: Client-7b8fa414-1448-11ee-8025-5cff35c1a711
2023-06-26 17:41:36,872 - distributed.scheduler - INFO - Receive client connection: Client-b3038684-1448-11ee-855d-5cff35c1a711
2023-06-26 17:41:36,872 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:59728
2023-06-26 17:41:36,908 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 17:42:27,693 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 17:42:45,870 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 17:42:45,871 - distributed.scheduler - INFO - Restarting workers and releasing all keys.
2023-06-26 17:42:45,893 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37018; closing.
2023-06-26 17:42:45,893 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34335', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,894 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34335
2023-06-26 17:42:45,895 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37124; closing.
2023-06-26 17:42:45,895 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35841', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,896 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35841
2023-06-26 17:42:45,896 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37144; closing.
2023-06-26 17:42:45,896 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37084; closing.
2023-06-26 17:42:45,897 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37359', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,897 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37359
2023-06-26 17:42:45,897 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37485', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,897 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37485
2023-06-26 17:42:45,897 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37102; closing.
2023-06-26 17:42:45,898 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38969', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,898 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38969
2023-06-26 17:42:45,898 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37110; closing.
2023-06-26 17:42:45,899 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37036; closing.
2023-06-26 17:42:45,899 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39363', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,899 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39363
2023-06-26 17:42:45,900 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39527', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,900 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39527
2023-06-26 17:42:45,900 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37054; closing.
2023-06-26 17:42:45,901 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39707', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,901 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39707
2023-06-26 17:42:45,902 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37068; closing.
2023-06-26 17:42:45,902 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40029', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,902 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40029
2023-06-26 17:42:45,904 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37044; closing.
2023-06-26 17:42:45,905 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40729', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,905 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40729
2023-06-26 17:42:45,905 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36968; closing.
2023-06-26 17:42:45,906 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41311', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,906 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41311
2023-06-26 17:42:45,906 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37024; closing.
2023-06-26 17:42:45,906 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41223', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,906 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41223
2023-06-26 17:42:45,906 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37136; closing.
2023-06-26 17:42:45,907 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41725', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,907 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41725
2023-06-26 17:42:45,921 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37004; closing.
2023-06-26 17:42:45,921 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42241', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,921 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42241
2023-06-26 17:42:45,923 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37006; closing.
2023-06-26 17:42:45,923 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46755', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,923 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46755
2023-06-26 17:42:45,929 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:37092; closing.
2023-06-26 17:42:45,929 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44405', status: closing, memory: 0, processing: 0>
2023-06-26 17:42:45,929 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44405
2023-06-26 17:42:45,929 - distributed.scheduler - INFO - Lost all workers
2023-06-26 17:42:58,412 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:36489', status: init, memory: 0, processing: 0>
2023-06-26 17:42:58,412 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:36489
2023-06-26 17:42:58,413 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47140
2023-06-26 17:43:00,603 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45963', status: init, memory: 0, processing: 0>
2023-06-26 17:43:00,603 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45963
2023-06-26 17:43:00,603 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:42982
2023-06-26 17:43:01,293 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33657', status: init, memory: 0, processing: 0>
2023-06-26 17:43:01,294 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33657
2023-06-26 17:43:01,294 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:42996
2023-06-26 17:43:01,502 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35677', status: init, memory: 0, processing: 0>
2023-06-26 17:43:01,502 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35677
2023-06-26 17:43:01,502 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43004
2023-06-26 17:43:01,520 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34911', status: init, memory: 0, processing: 0>
2023-06-26 17:43:01,520 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34911
2023-06-26 17:43:01,520 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43018
2023-06-26 17:43:01,541 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35299', status: init, memory: 0, processing: 0>
2023-06-26 17:43:01,541 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35299
2023-06-26 17:43:01,541 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43032
2023-06-26 17:43:01,562 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40151', status: init, memory: 0, processing: 0>
2023-06-26 17:43:01,562 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40151
2023-06-26 17:43:01,562 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43048
2023-06-26 17:43:01,609 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42037', status: init, memory: 0, processing: 0>
2023-06-26 17:43:01,609 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42037
2023-06-26 17:43:01,609 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43058
2023-06-26 17:43:04,515 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34159', status: init, memory: 0, processing: 0>
2023-06-26 17:43:04,515 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34159
2023-06-26 17:43:04,515 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43116
2023-06-26 17:43:04,654 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46237', status: init, memory: 0, processing: 0>
2023-06-26 17:43:04,654 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46237
2023-06-26 17:43:04,654 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43130
2023-06-26 17:43:05,043 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44057', status: init, memory: 0, processing: 0>
2023-06-26 17:43:05,044 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44057
2023-06-26 17:43:05,044 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43136
2023-06-26 17:43:05,049 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42641', status: init, memory: 0, processing: 0>
2023-06-26 17:43:05,050 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42641
2023-06-26 17:43:05,050 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43138
2023-06-26 17:43:05,055 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:43723', status: init, memory: 0, processing: 0>
2023-06-26 17:43:05,056 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:43723
2023-06-26 17:43:05,056 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43142
2023-06-26 17:43:05,076 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38655', status: init, memory: 0, processing: 0>
2023-06-26 17:43:05,077 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38655
2023-06-26 17:43:05,077 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43154
2023-06-26 17:43:05,082 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38569', status: init, memory: 0, processing: 0>
2023-06-26 17:43:05,082 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38569
2023-06-26 17:43:05,082 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43168
2023-06-26 17:43:05,084 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42497', status: init, memory: 0, processing: 0>
2023-06-26 17:43:05,085 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42497
2023-06-26 17:43:05,085 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:43164
2023-06-26 17:43:05,142 - distributed.scheduler - INFO - Restarting finished.
2023-06-26 17:43:15,087 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 17:43:41,122 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 17:43:41,123 - distributed.scheduler - INFO - Remove client Client-b3038684-1448-11ee-855d-5cff35c1a711
2023-06-26 17:43:41,123 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:59728; closing.
2023-06-26 17:43:41,123 - distributed.scheduler - INFO - Remove client Client-b3038684-1448-11ee-855d-5cff35c1a711
2023-06-26 17:43:41,123 - distributed.scheduler - INFO - Close client connection: Client-b3038684-1448-11ee-855d-5cff35c1a711
2023-06-26 18:03:01,066 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 18:03:01,067 - distributed.core - INFO - Connection to tcp://10.120.104.11:43164 has been closed.
2023-06-26 18:03:01,067 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42497', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,067 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42497
2023-06-26 18:03:01,067 - distributed.core - INFO - Connection to tcp://10.120.104.11:43130 has been closed.
2023-06-26 18:03:01,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46237', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46237
2023-06-26 18:03:01,068 - distributed.core - INFO - Connection to tcp://10.120.104.11:43136 has been closed.
2023-06-26 18:03:01,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44057', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44057
2023-06-26 18:03:01,068 - distributed.core - INFO - Connection to tcp://10.120.104.11:43138 has been closed.
2023-06-26 18:03:01,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42641', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42641
2023-06-26 18:03:01,068 - distributed.core - INFO - Connection to tcp://10.120.104.11:43168 has been closed.
2023-06-26 18:03:01,068 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38569', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,068 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38569
2023-06-26 18:03:01,069 - distributed.core - INFO - Connection to tcp://10.120.104.11:43142 has been closed.
2023-06-26 18:03:01,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:43723', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,069 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43723
2023-06-26 18:03:01,069 - distributed.core - INFO - Connection to tcp://10.120.104.11:43154 has been closed.
2023-06-26 18:03:01,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38655', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,069 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38655
2023-06-26 18:03:01,069 - distributed.core - INFO - Connection to tcp://10.120.104.11:47140 has been closed.
2023-06-26 18:03:01,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:36489', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,069 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36489
2023-06-26 18:03:01,069 - distributed.core - INFO - Connection to tcp://10.120.104.11:43116 has been closed.
2023-06-26 18:03:01,069 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34159', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,069 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34159
2023-06-26 18:03:01,070 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 18:03:01,070 - distributed.core - INFO - Connection to tcp://10.120.104.11:42982 has been closed.
2023-06-26 18:03:01,071 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45963', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,071 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45963
2023-06-26 18:03:01,071 - distributed.core - INFO - Connection to tcp://10.120.104.11:43018 has been closed.
2023-06-26 18:03:01,071 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34911', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,071 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34911
2023-06-26 18:03:01,071 - distributed.core - INFO - Connection to tcp://10.120.104.11:43004 has been closed.
2023-06-26 18:03:01,071 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35677', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,071 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35677
2023-06-26 18:03:01,072 - distributed.core - INFO - Connection to tcp://10.120.104.11:43058 has been closed.
2023-06-26 18:03:01,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42037', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,072 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42037
2023-06-26 18:03:01,072 - distributed.core - INFO - Connection to tcp://10.120.104.11:43032 has been closed.
2023-06-26 18:03:01,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35299', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,072 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35299
2023-06-26 18:03:01,072 - distributed.core - INFO - Connection to tcp://10.120.104.11:42996 has been closed.
2023-06-26 18:03:01,072 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33657', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,073 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33657
2023-06-26 18:03:01,073 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:42996>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:42996>: Stream is closed
2023-06-26 18:03:01,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:43018>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:03:01,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:43032>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:43032>: Stream is closed
2023-06-26 18:03:01,074 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:43004>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:03:01,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:43058>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:43058>: Stream is closed
2023-06-26 18:03:01,075 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:42982>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:03:01,075 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 18:03:01,076 - distributed.core - INFO - Connection to tcp://10.120.104.11:43048 has been closed.
2023-06-26 18:03:01,076 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40151', status: running, memory: 0, processing: 0>
2023-06-26 18:03:01,076 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40151
2023-06-26 18:03:01,076 - distributed.scheduler - INFO - Lost all workers
2023-06-26 18:03:01,079 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 18:03:01,079 - distributed.scheduler - INFO - End scheduler
