RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/work/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-22 20:29:45,691 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 20:29:46,149 - distributed.scheduler - INFO - State start
2023-06-22 20:29:46,150 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ax2b9mit', purging
2023-06-22 20:29:46,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3m14qkdw', purging
2023-06-22 20:29:46,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-t52mvm47', purging
2023-06-22 20:29:46,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-a9slc3te', purging
2023-06-22 20:29:46,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-tl6wxgle', purging
2023-06-22 20:29:46,151 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-o1nnxjgp', purging
2023-06-22 20:29:46,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-v1v32ju9', purging
2023-06-22 20:29:46,152 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-8v1uxggg', purging
2023-06-22 20:29:46,161 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 20:29:46,161 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.169:8786
2023-06-22 20:29:46,162 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.169:8787/status
2023-06-22 20:29:57,226 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:46683', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,522 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:46683
2023-06-22 20:29:57,522 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51592
2023-06-22 20:29:57,524 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:39375', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,524 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:39375
2023-06-22 20:29:57,524 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51598
2023-06-22 20:29:57,532 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:37353', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,533 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:37353
2023-06-22 20:29:57,533 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51602
2023-06-22 20:29:57,533 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:34095', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,534 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:34095
2023-06-22 20:29:57,534 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51614
2023-06-22 20:29:57,535 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:41847', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,535 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:41847
2023-06-22 20:29:57,535 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51604
2023-06-22 20:29:57,536 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:39467', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,537 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:39467
2023-06-22 20:29:57,537 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51634
2023-06-22 20:29:57,537 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:36061', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,538 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:36061
2023-06-22 20:29:57,538 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51628
2023-06-22 20:29:57,539 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:37227', status: init, memory: 0, processing: 0>
2023-06-22 20:29:57,539 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:37227
2023-06-22 20:29:57,539 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51636
2023-06-22 20:30:17,368 - distributed.scheduler - INFO - Receive client connection: Client-99a5efd3-113b-11ee-9854-d8c49778ced7
2023-06-22 20:30:17,369 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:52278
2023-06-22 20:30:17,477 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-22 20:31:06,990 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 20:31:09,131 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-22 20:31:12,953 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 20:32:53,745 - distributed.scheduler - INFO - Remove client Client-99a5efd3-113b-11ee-9854-d8c49778ced7
2023-06-22 20:32:53,749 - distributed.core - INFO - Received 'close-stream' from tcp://10.33.227.169:52278; closing.
2023-06-22 20:32:53,749 - distributed.scheduler - INFO - Remove client Client-99a5efd3-113b-11ee-9854-d8c49778ced7
2023-06-22 20:32:53,751 - distributed.scheduler - INFO - Close client connection: Client-99a5efd3-113b-11ee-9854-d8c49778ced7
2023-06-22 20:33:00,671 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-22 20:33:00,672 - distributed.core - INFO - Connection to tcp://10.33.227.169:51598 has been closed.
2023-06-22 20:33:00,672 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:39375', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,673 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:39375
2023-06-22 20:33:00,674 - distributed.scheduler - INFO - Scheduler closing...
2023-06-22 20:33:00,675 - distributed.core - INFO - Connection to tcp://10.33.227.169:51614 has been closed.
2023-06-22 20:33:00,675 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:34095', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,675 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:34095
2023-06-22 20:33:00,675 - distributed.core - INFO - Connection to tcp://10.33.227.169:51592 has been closed.
2023-06-22 20:33:00,675 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:46683', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,676 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:46683
2023-06-22 20:33:00,676 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51614>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51614>: Stream is closed
2023-06-22 20:33:00,677 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51592>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51592>: Stream is closed
2023-06-22 20:33:00,678 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-22 20:33:00,679 - distributed.core - INFO - Connection to tcp://10.33.227.169:51602 has been closed.
2023-06-22 20:33:00,679 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:37353', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,679 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:37353
2023-06-22 20:33:00,680 - distributed.core - INFO - Connection to tcp://10.33.227.169:51604 has been closed.
2023-06-22 20:33:00,680 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:41847', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,680 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:41847
2023-06-22 20:33:00,680 - distributed.core - INFO - Connection to tcp://10.33.227.169:51634 has been closed.
2023-06-22 20:33:00,680 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:39467', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,680 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:39467
2023-06-22 20:33:00,681 - distributed.core - INFO - Connection to tcp://10.33.227.169:51628 has been closed.
2023-06-22 20:33:00,681 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:36061', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,681 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:36061
2023-06-22 20:33:00,681 - distributed.core - INFO - Connection to tcp://10.33.227.169:51636 has been closed.
2023-06-22 20:33:00,681 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:37227', status: running, memory: 0, processing: 0>
2023-06-22 20:33:00,681 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:37227
2023-06-22 20:33:00,681 - distributed.scheduler - INFO - Lost all workers
2023-06-22 20:33:01,547 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.169:8786'
2023-06-22 20:33:01,548 - distributed.scheduler - INFO - End scheduler
sys:1: RuntimeWarning: coroutine 'WSHandler.send_message' was never awaited
