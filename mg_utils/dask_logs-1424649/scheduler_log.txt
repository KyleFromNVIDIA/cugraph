RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/work/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-22 21:29:56,024 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 21:29:56,486 - distributed.scheduler - INFO - State start
2023-06-22 21:29:56,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-0yt_cx2x', purging
2023-06-22 21:29:56,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-t_gpm9dk', purging
2023-06-22 21:29:56,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ouhmj9b9', purging
2023-06-22 21:29:56,487 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-q0z6irjx', purging
2023-06-22 21:29:56,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-7hnj6ew5', purging
2023-06-22 21:29:56,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vwh_irom', purging
2023-06-22 21:29:56,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-lslqeeid', purging
2023-06-22 21:29:56,488 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-r3bt28xw', purging
2023-06-22 21:29:56,497 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 21:29:56,498 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.169:8786
2023-06-22 21:29:56,498 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.169:8787/status
2023-06-22 21:30:06,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:39679', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,100 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:39679
2023-06-22 21:30:07,100 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59734
2023-06-22 21:30:07,294 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:45355', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,295 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:45355
2023-06-22 21:30:07,295 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59750
2023-06-22 21:30:07,648 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:37139', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,648 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:37139
2023-06-22 21:30:07,648 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59764
2023-06-22 21:30:07,648 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:38713', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,649 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:38713
2023-06-22 21:30:07,649 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59762
2023-06-22 21:30:07,649 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:33261', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,650 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:33261
2023-06-22 21:30:07,650 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59776
2023-06-22 21:30:07,652 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:33259', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,652 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:33259
2023-06-22 21:30:07,652 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59790
2023-06-22 21:30:07,653 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:42333', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,653 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:42333
2023-06-22 21:30:07,653 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59792
2023-06-22 21:30:07,655 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:42829', status: init, memory: 0, processing: 0>
2023-06-22 21:30:07,655 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:42829
2023-06-22 21:30:07,655 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:59804
2023-06-22 21:30:08,722 - distributed.scheduler - INFO - Receive client connection: Client-f6432181-1143-11ee-bd68-d8c49778ced7
2023-06-22 21:30:08,723 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:52956
2023-06-22 21:30:08,826 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-22 21:30:58,104 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 21:31:00,282 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-22 21:31:04,215 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 21:31:08,993 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-22 21:31:08,995 - distributed.scheduler - INFO - Remove client Client-f6432181-1143-11ee-bd68-d8c49778ced7
2023-06-22 21:31:09,001 - distributed.core - INFO - Received 'close-stream' from tcp://10.33.227.169:52956; closing.
2023-06-22 21:31:09,002 - distributed.scheduler - INFO - Remove client Client-f6432181-1143-11ee-bd68-d8c49778ced7
2023-06-22 21:31:09,005 - distributed.scheduler - INFO - Close client connection: Client-f6432181-1143-11ee-bd68-d8c49778ced7
2023-06-22 21:32:50,364 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-22 21:32:50,365 - distributed.core - INFO - Connection to tcp://10.33.227.169:59750 has been closed.
2023-06-22 21:32:50,365 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:45355', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,366 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:45355
2023-06-22 21:32:50,366 - distributed.core - INFO - Connection to tcp://10.33.227.169:59776 has been closed.
2023-06-22 21:32:50,366 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:33261', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,367 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:33261
2023-06-22 21:32:50,367 - distributed.core - INFO - Connection to tcp://10.33.227.169:59734 has been closed.
2023-06-22 21:32:50,367 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:39679', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,367 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:39679
2023-06-22 21:32:50,368 - distributed.scheduler - INFO - Scheduler closing...
2023-06-22 21:32:50,368 - distributed.core - INFO - Connection to tcp://10.33.227.169:59764 has been closed.
2023-06-22 21:32:50,369 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:37139', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,369 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:37139
2023-06-22 21:32:50,369 - distributed.core - INFO - Connection to tcp://10.33.227.169:59804 has been closed.
2023-06-22 21:32:50,369 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:42829', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,369 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:42829
2023-06-22 21:32:50,369 - distributed.core - INFO - Connection to tcp://10.33.227.169:59792 has been closed.
2023-06-22 21:32:50,369 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:42333', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,370 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:42333
2023-06-22 21:32:50,370 - distributed.core - INFO - Connection to tcp://10.33.227.169:59790 has been closed.
2023-06-22 21:32:50,370 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:33259', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,371 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:33259
2023-06-22 21:32:50,371 - distributed.core - INFO - Connection to tcp://10.33.227.169:59762 has been closed.
2023-06-22 21:32:50,371 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:38713', status: running, memory: 0, processing: 0>
2023-06-22 21:32:50,371 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:38713
2023-06-22 21:32:50,371 - distributed.scheduler - INFO - Lost all workers
2023-06-22 21:32:50,372 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59790>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59790>: Stream is closed
2023-06-22 21:32:50,373 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59764>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 21:32:50,373 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59762>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59762>: Stream is closed
2023-06-22 21:32:50,374 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59792>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 21:32:50,374 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:59804>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 21:32:50,375 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-22 21:32:50,377 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.169:8786'
2023-06-22 21:32:50,378 - distributed.scheduler - INFO - End scheduler
