RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/work/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-22 23:03:48,865 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 23:03:49,360 - distributed.scheduler - INFO - State start
2023-06-22 23:03:49,371 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 23:03:49,372 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.169:8786
2023-06-22 23:03:49,372 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.169:8787/status
2023-06-22 23:03:59,274 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:35245', status: init, memory: 0, processing: 0>
2023-06-22 23:03:59,538 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:35245
2023-06-22 23:03:59,538 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51080
2023-06-22 23:04:00,323 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:32913', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,323 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:32913
2023-06-22 23:04:00,323 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51088
2023-06-22 23:04:00,331 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:36395', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,331 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:36395
2023-06-22 23:04:00,332 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51100
2023-06-22 23:04:00,332 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:38961', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,332 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:38961
2023-06-22 23:04:00,332 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51102
2023-06-22 23:04:00,336 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:33831', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,337 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:33831
2023-06-22 23:04:00,337 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51118
2023-06-22 23:04:00,337 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:35193', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,338 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:35193
2023-06-22 23:04:00,338 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51124
2023-06-22 23:04:00,375 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:44065', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,375 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:44065
2023-06-22 23:04:00,376 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51140
2023-06-22 23:04:00,376 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:34973', status: init, memory: 0, processing: 0>
2023-06-22 23:04:00,377 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:34973
2023-06-22 23:04:00,377 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51150
2023-06-22 23:04:01,463 - distributed.scheduler - INFO - Receive client connection: Client-13a34f18-1151-11ee-96d9-d8c49778ced7
2023-06-22 23:04:01,464 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51246
2023-06-22 23:04:01,566 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-22 23:04:49,626 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 23:04:52,073 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-22 23:04:56,017 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 23:06:20,369 - distributed.scheduler - INFO - Remove client Client-13a34f18-1151-11ee-96d9-d8c49778ced7
2023-06-22 23:06:20,373 - distributed.core - INFO - Received 'close-stream' from tcp://10.33.227.169:51246; closing.
2023-06-22 23:06:20,374 - distributed.scheduler - INFO - Remove client Client-13a34f18-1151-11ee-96d9-d8c49778ced7
2023-06-22 23:06:20,377 - distributed.scheduler - INFO - Close client connection: Client-13a34f18-1151-11ee-96d9-d8c49778ced7
2023-06-22 23:06:26,213 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-22 23:06:26,214 - distributed.core - INFO - Connection to tcp://10.33.227.169:51100 has been closed.
2023-06-22 23:06:26,214 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:36395', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,216 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:36395
2023-06-22 23:06:26,216 - distributed.core - INFO - Connection to tcp://10.33.227.169:51124 has been closed.
2023-06-22 23:06:26,216 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:35193', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,217 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:35193
2023-06-22 23:06:26,217 - distributed.core - INFO - Connection to tcp://10.33.227.169:51140 has been closed.
2023-06-22 23:06:26,217 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:44065', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,217 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:44065
2023-06-22 23:06:26,217 - distributed.core - INFO - Connection to tcp://10.33.227.169:51102 has been closed.
2023-06-22 23:06:26,217 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:38961', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,217 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:38961
2023-06-22 23:06:26,218 - distributed.scheduler - INFO - Scheduler closing...
2023-06-22 23:06:26,219 - distributed.core - INFO - Connection to tcp://10.33.227.169:51150 has been closed.
2023-06-22 23:06:26,219 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:34973', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,219 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:34973
2023-06-22 23:06:26,220 - distributed.core - INFO - Connection to tcp://10.33.227.169:51080 has been closed.
2023-06-22 23:06:26,220 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:35245', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,221 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:35245
2023-06-22 23:06:26,221 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51150>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 23:06:26,222 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51080>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51080>: Stream is closed
2023-06-22 23:06:26,223 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-22 23:06:26,224 - distributed.core - INFO - Connection to tcp://10.33.227.169:51088 has been closed.
2023-06-22 23:06:26,224 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:32913', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,224 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:32913
2023-06-22 23:06:26,224 - distributed.core - INFO - Connection to tcp://10.33.227.169:51118 has been closed.
2023-06-22 23:06:26,224 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:33831', status: running, memory: 0, processing: 0>
2023-06-22 23:06:26,225 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:33831
2023-06-22 23:06:26,225 - distributed.scheduler - INFO - Lost all workers
2023-06-22 23:06:26,226 - distributed.scheduler - ERROR - broadcast to tcp://10.33.227.169:32913 failed: CommClosedError: Address removed.
2023-06-22 23:06:26,226 - tornado.application - ERROR - Uncaught exception GET /info/logs/tcp%3A%2F%2F10.33.227.169%3A32913.html (10.20.237.237)
HTTPServerRequest(protocol='http', host='10.33.227.169:8787', method='GET', uri='/info/logs/tcp%3A%2F%2F10.33.227.169%3A32913.html', version='HTTP/1.1', remote_ip='10.20.237.237')
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1527, in _connect
    comm = await connect(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 373, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 1878, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 441, in wait_for
    await _cancel_and_wait(fut, loop=loop)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 518, in _cancel_and_wait
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/web.py", line 1786, in _execute
    result = await result
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/http/scheduler/info.py", line 127, in get
    logs = await self.server.get_worker_logs(workers=[worker])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 7878, in get_worker_logs
    results = await self.broadcast(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6124, in broadcast
    results = await All(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 249, in All
    result = await tasks.next()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6099, in send_message
    comm = await self.rpc.connect(addr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1606, in connect
    return await connect_attempt
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1550, in _connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: Address removed.
2023-06-22 23:06:27,038 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.169:8786'
2023-06-22 23:06:27,038 - distributed.scheduler - INFO - End scheduler
