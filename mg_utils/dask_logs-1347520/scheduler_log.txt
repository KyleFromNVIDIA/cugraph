RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/work/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-22 19:40:50,622 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 19:40:51,393 - distributed.scheduler - INFO - State start
2023-06-22 19:40:51,394 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-47hf717s', purging
2023-06-22 19:40:51,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-8c20ur6y', purging
2023-06-22 19:40:51,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ae2j9g8p', purging
2023-06-22 19:40:51,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-jh_vx9tc', purging
2023-06-22 19:40:51,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-iuc4shwt', purging
2023-06-22 19:40:51,395 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-szip8dqw', purging
2023-06-22 19:40:51,396 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-s1qfxqyu', purging
2023-06-22 19:40:51,407 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 19:40:51,408 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.169:8786
2023-06-22 19:40:51,408 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.169:8787/status
2023-06-22 19:41:02,522 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:44491', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,773 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:44491
2023-06-22 19:41:02,773 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51736
2023-06-22 19:41:02,774 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:34817', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,774 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:34817
2023-06-22 19:41:02,774 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51744
2023-06-22 19:41:02,775 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:43263', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,775 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:43263
2023-06-22 19:41:02,776 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51758
2023-06-22 19:41:02,776 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:42947', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,776 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:42947
2023-06-22 19:41:02,776 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51746
2023-06-22 19:41:02,777 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:46569', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,777 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:46569
2023-06-22 19:41:02,777 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51760
2023-06-22 19:41:02,778 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:42761', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,778 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:42761
2023-06-22 19:41:02,778 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51776
2023-06-22 19:41:02,790 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:42051', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,790 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:42051
2023-06-22 19:41:02,790 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51796
2023-06-22 19:41:02,791 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:42095', status: init, memory: 0, processing: 0>
2023-06-22 19:41:02,791 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:42095
2023-06-22 19:41:02,791 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:51786
2023-06-22 19:41:23,995 - distributed.scheduler - INFO - Receive client connection: Client-c538e2c5-1134-11ee-9182-d8c49778ced7
2023-06-22 19:41:23,996 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:50508
2023-06-22 19:41:24,106 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-22 19:42:12,216 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 19:42:14,391 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-22 19:42:18,208 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 19:42:18,371 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a2ab81-1134-11ee-9068-d8c49778ced7
2023-06-22 19:42:18,372 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38758
2023-06-22 19:42:18,396 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a5e432-1134-11ee-9076-d8c49778ced7
2023-06-22 19:42:18,396 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38768
2023-06-22 19:42:18,397 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a5efa4-1134-11ee-9065-d8c49778ced7
2023-06-22 19:42:18,398 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38782
2023-06-22 19:42:18,398 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a5f3b7-1134-11ee-906c-d8c49778ced7
2023-06-22 19:42:18,398 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38792
2023-06-22 19:42:18,399 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a5f6d9-1134-11ee-907c-d8c49778ced7
2023-06-22 19:42:18,399 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38794
2023-06-22 19:42:18,399 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a5f620-1134-11ee-907e-d8c49778ced7
2023-06-22 19:42:18,400 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38802
2023-06-22 19:42:18,401 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a6019e-1134-11ee-9071-d8c49778ced7
2023-06-22 19:42:18,402 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38814
2023-06-22 19:42:18,404 - distributed.scheduler - INFO - Receive client connection: Client-worker-e5a5f141-1134-11ee-9062-d8c49778ced7
2023-06-22 19:42:18,404 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:38824
2023-06-22 19:44:41,235 - distributed.scheduler - ERROR - broadcast to tcp://10.33.227.169:34817 failed: OSError: Timed out during handshake while connecting to tcp://10.33.227.169:34817 after 100 s
2023-06-22 19:44:41,241 - tornado.application - ERROR - Uncaught exception GET /info/logs/tcp%3A%2F%2F10.33.227.169%3A34817.html (10.20.237.237)
HTTPServerRequest(protocol='http', host='10.33.227.169:8787', method='GET', uri='/info/logs/tcp%3A%2F%2F10.33.227.169%3A34817.html', version='HTTP/1.1', remote_ip='10.20.237.237')
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 456, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 373, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 1878, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 458, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/web.py", line 1786, in _execute
    result = await result
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/http/scheduler/info.py", line 127, in get
    logs = await self.server.get_worker_logs(workers=[worker])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 7878, in get_worker_logs
    results = await self.broadcast(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6124, in broadcast
    results = await All(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 249, in All
    result = await tasks.next()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6099, in send_message
    comm = await self.rpc.connect(addr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1606, in connect
    return await connect_attempt
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1527, in _connect
    comm = await connect(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 378, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://10.33.227.169:34817 after 100 s
2023-06-22 19:44:49,450 - distributed.scheduler - ERROR - broadcast to tcp://10.33.227.169:42051 failed: OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42051 after 100 s
2023-06-22 19:44:49,451 - tornado.application - ERROR - Uncaught exception GET /info/logs/tcp%3A%2F%2F10.33.227.169%3A42051.html (10.20.237.237)
HTTPServerRequest(protocol='http', host='10.33.227.169:8787', method='GET', uri='/info/logs/tcp%3A%2F%2F10.33.227.169%3A42051.html', version='HTTP/1.1', remote_ip='10.20.237.237')
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 456, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 373, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 1878, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 458, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/web.py", line 1786, in _execute
    result = await result
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/http/scheduler/info.py", line 127, in get
    logs = await self.server.get_worker_logs(workers=[worker])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 7878, in get_worker_logs
    results = await self.broadcast(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6124, in broadcast
    results = await All(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 249, in All
    result = await tasks.next()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6099, in send_message
    comm = await self.rpc.connect(addr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1606, in connect
    return await connect_attempt
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1527, in _connect
    comm = await connect(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 378, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42051 after 100 s
2023-06-22 19:45:01,384 - distributed.scheduler - ERROR - broadcast to tcp://10.33.227.169:42095 failed: OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42095 after 100 s
2023-06-22 19:45:01,385 - tornado.application - ERROR - Uncaught exception GET /info/logs/tcp%3A%2F%2F10.33.227.169%3A42095.html (10.20.237.237)
HTTPServerRequest(protocol='http', host='10.33.227.169:8787', method='GET', uri='/info/logs/tcp%3A%2F%2F10.33.227.169%3A42095.html', version='HTTP/1.1', remote_ip='10.20.237.237')
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 456, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 373, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 1878, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 458, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/web.py", line 1786, in _execute
    result = await result
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/http/scheduler/info.py", line 127, in get
    logs = await self.server.get_worker_logs(workers=[worker])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 7878, in get_worker_logs
    results = await self.broadcast(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6124, in broadcast
    results = await All(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 249, in All
    result = await tasks.next()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6099, in send_message
    comm = await self.rpc.connect(addr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1606, in connect
    return await connect_attempt
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1527, in _connect
    comm = await connect(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 378, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42095 after 100 s
2023-06-22 19:45:01,583 - distributed.scheduler - ERROR - broadcast to tcp://10.33.227.169:42095 failed: OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42095 after 100 s
2023-06-22 19:45:01,584 - tornado.application - ERROR - Uncaught exception GET /info/logs/tcp%3A%2F%2F10.33.227.169%3A42095.html (10.20.237.237)
HTTPServerRequest(protocol='http', host='10.33.227.169:8787', method='GET', uri='/info/logs/tcp%3A%2F%2F10.33.227.169%3A42095.html', version='HTTP/1.1', remote_ip='10.20.237.237')
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 456, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 373, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 1878, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 458, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/web.py", line 1786, in _execute
    result = await result
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/http/scheduler/info.py", line 127, in get
    logs = await self.server.get_worker_logs(workers=[worker])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 7878, in get_worker_logs
    results = await self.broadcast(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6124, in broadcast
    results = await All(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 249, in All
    result = await tasks.next()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6099, in send_message
    comm = await self.rpc.connect(addr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1606, in connect
    return await connect_attempt
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1527, in _connect
    comm = await connect(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 378, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42095 after 100 s
2023-06-22 19:45:01,751 - distributed.scheduler - ERROR - broadcast to tcp://10.33.227.169:42095 failed: OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42095 after 100 s
2023-06-22 19:45:01,751 - tornado.application - ERROR - Uncaught exception GET /info/logs/tcp%3A%2F%2F10.33.227.169%3A42095.html (10.20.237.237)
HTTPServerRequest(protocol='http', host='10.33.227.169:8787', method='GET', uri='/info/logs/tcp%3A%2F%2F10.33.227.169%3A42095.html', version='HTTP/1.1', remote_ip='10.20.237.237')
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 456, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 373, in connect
    handshake = await wait_for(comm.read(), time_left())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 1878, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/rapids/lib/python3.10/asyncio/tasks.py", line 458, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/web.py", line 1786, in _execute
    result = await result
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/http/scheduler/info.py", line 127, in get
    logs = await self.server.get_worker_logs(workers=[worker])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 7878, in get_worker_logs
    results = await self.broadcast(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6124, in broadcast
    results = await All(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 249, in All
    result = await tasks.next()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 6099, in send_message
    comm = await self.rpc.connect(addr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1606, in connect
    return await connect_attempt
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 1527, in _connect
    comm = await connect(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/core.py", line 378, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://10.33.227.169:42095 after 100 s
2023-06-22 19:50:51,409 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://10.33.227.169:34817', status: running, memory: 2, processing: 1>
2023-06-22 19:50:51,410 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:34817', status: running, memory: 2, processing: 1>
2023-06-22 19:50:51,412 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:34817
2023-06-22 19:50:51,414 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://10.33.227.169:42095', status: running, memory: 2, processing: 1>
2023-06-22 19:50:51,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:42095', status: running, memory: 2, processing: 1>
2023-06-22 19:50:51,414 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:42095
2023-06-22 19:50:51,415 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://10.33.227.169:43263', status: running, memory: 2, processing: 1>
2023-06-22 19:50:51,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:43263', status: running, memory: 2, processing: 1>
2023-06-22 19:50:51,415 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:43263
2023-06-22 19:50:51,415 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://10.33.227.169:46569', status: running, memory: 3, processing: 1>
2023-06-22 19:50:51,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:46569', status: running, memory: 3, processing: 1>
2023-06-22 19:50:51,415 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:46569
2023-06-22 19:55:51,411 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://10.33.227.169:42051', status: running, memory: 2, processing: 2>
2023-06-22 19:55:51,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:42051', status: running, memory: 2, processing: 2>
2023-06-22 19:55:51,412 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:42051
2023-06-22 20:00:51,411 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://10.33.227.169:42761', status: running, memory: 3, processing: 1>
2023-06-22 20:00:51,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:42761', status: running, memory: 3, processing: 1>
2023-06-22 20:00:51,412 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:42761
2023-06-22 20:07:28,460 - distributed.scheduler - INFO - Remove client Client-c538e2c5-1134-11ee-9182-d8c49778ced7
2023-06-22 20:07:28,465 - distributed.core - INFO - Received 'close-stream' from tcp://10.33.227.169:50508; closing.
2023-06-22 20:07:28,470 - distributed.scheduler - INFO - Remove client Client-c538e2c5-1134-11ee-9182-d8c49778ced7
2023-06-22 20:07:28,471 - distributed.scheduler - INFO - Close client connection: Client-c538e2c5-1134-11ee-9182-d8c49778ced7
2023-06-22 20:08:13,001 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-22 20:08:13,001 - distributed.scheduler - INFO - Scheduler closing...
2023-06-22 20:08:13,002 - distributed.core - INFO - Connection to tcp://10.33.227.169:38794 has been closed.
2023-06-22 20:08:13,003 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-22 20:08:13,003 - distributed.core - INFO - Connection to tcp://10.33.227.169:38802 has been closed.
2023-06-22 20:08:13,004 - distributed.core - INFO - Connection to tcp://10.33.227.169:51746 has been closed.
2023-06-22 20:08:13,004 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:42947', status: running, memory: 1, processing: 0>
2023-06-22 20:08:13,004 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:42947
2023-06-22 20:08:13,005 - distributed.core - INFO - Connection to tcp://10.33.227.169:51736 has been closed.
2023-06-22 20:08:13,005 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:44491', status: running, memory: 0, processing: 1>
2023-06-22 20:08:13,005 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:44491
2023-06-22 20:08:13,005 - distributed.scheduler - INFO - Lost all workers
2023-06-22 20:08:13,006 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51736>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 20:08:13,008 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:51746>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 20:08:13,012 - distributed.core - ERROR - 
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 4303, in add_worker
    await self.handle_worker(comm, address)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 5669, in handle_worker
    await self.handle_stream(comm=comm, extra={"worker": worker})
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 977, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError
2023-06-22 20:08:13,012 - distributed.core - ERROR - 
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 4303, in add_worker
    await self.handle_worker(comm, address)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 5669, in handle_worker
    await self.handle_stream(comm=comm, extra={"worker": worker})
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 977, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError
2023-06-22 20:08:13,013 - distributed.core - ERROR - 
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 4303, in add_worker
    await self.handle_worker(comm, address)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 5669, in handle_worker
    await self.handle_stream(comm=comm, extra={"worker": worker})
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 977, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError
2023-06-22 20:08:13,014 - distributed.core - ERROR - 
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 4303, in add_worker
    await self.handle_worker(comm, address)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 5669, in handle_worker
    await self.handle_stream(comm=comm, extra={"worker": worker})
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 977, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError
2023-06-22 20:08:13,016 - distributed.core - ERROR - 
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 4303, in add_worker
    await self.handle_worker(comm, address)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 5669, in handle_worker
    await self.handle_stream(comm=comm, extra={"worker": worker})
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 977, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError
2023-06-22 20:08:13,017 - distributed.core - ERROR - 
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py", line 754, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 4303, in add_worker
    await self.handle_worker(comm, address)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/scheduler.py", line 5669, in handle_worker
    await self.handle_stream(comm=comm, extra={"worker": worker})
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/core.py", line 977, in handle_stream
    msgs = await comm.read()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError
2023-06-22 20:08:13,017 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.169:8786'
2023-06-22 20:08:13,018 - distributed.scheduler - INFO - End scheduler
