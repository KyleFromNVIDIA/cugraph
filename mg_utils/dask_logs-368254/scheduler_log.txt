RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 18:24:49,156 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 18:24:49,668 - distributed.scheduler - INFO - State start
2023-06-26 18:24:49,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3ow8sovq', purging
2023-06-26 18:24:49,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-qytq8978', purging
2023-06-26 18:24:49,669 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-uldu0cbz', purging
2023-06-26 18:24:49,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-jrm6gr44', purging
2023-06-26 18:24:49,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-0dy0iyzg', purging
2023-06-26 18:24:49,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-fuut69cx', purging
2023-06-26 18:24:49,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-83bb93ef', purging
2023-06-26 18:24:49,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-8ijb96ys', purging
2023-06-26 18:24:49,670 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ufu1q3us', purging
2023-06-26 18:24:49,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-khou4nwe', purging
2023-06-26 18:24:49,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-lx1x9d5_', purging
2023-06-26 18:24:49,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vfythfnt', purging
2023-06-26 18:24:49,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-efh56f7u', purging
2023-06-26 18:24:49,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-i9249tsk', purging
2023-06-26 18:24:49,671 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-1x1yd_q2', purging
2023-06-26 18:24:49,672 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ob6kx3nr', purging
2023-06-26 18:24:49,684 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 18:24:49,685 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 18:24:49,685 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 18:25:06,158 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41103', status: init, memory: 0, processing: 0>
2023-06-26 18:25:06,162 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41103
2023-06-26 18:25:06,162 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:42896
2023-06-26 18:25:07,588 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33579', status: init, memory: 0, processing: 0>
2023-06-26 18:25:07,588 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33579
2023-06-26 18:25:07,589 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:42922
2023-06-26 18:25:07,782 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45131', status: init, memory: 0, processing: 0>
2023-06-26 18:25:07,782 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45131
2023-06-26 18:25:07,782 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:42926
2023-06-26 18:25:08,641 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37517', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,642 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37517
2023-06-26 18:25:08,642 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:42944
2023-06-26 18:25:08,731 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33431', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,731 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33431
2023-06-26 18:25:08,731 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33572
2023-06-26 18:25:08,754 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40159', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,754 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40159
2023-06-26 18:25:08,754 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33586
2023-06-26 18:25:08,812 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46633', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,812 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46633
2023-06-26 18:25:08,812 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33606
2023-06-26 18:25:08,830 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35009', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,831 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35009
2023-06-26 18:25:08,831 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33616
2023-06-26 18:25:08,841 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44457', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,841 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44457
2023-06-26 18:25:08,841 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33618
2023-06-26 18:25:08,843 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40533', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,843 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40533
2023-06-26 18:25:08,843 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33632
2023-06-26 18:25:08,850 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42449', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,851 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42449
2023-06-26 18:25:08,851 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33636
2023-06-26 18:25:08,864 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35357', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,864 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35357
2023-06-26 18:25:08,864 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33650
2023-06-26 18:25:08,867 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39719', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,867 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39719
2023-06-26 18:25:08,867 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33652
2023-06-26 18:25:08,873 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35323', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,874 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35323
2023-06-26 18:25:08,874 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33668
2023-06-26 18:25:08,889 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44331', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,889 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44331
2023-06-26 18:25:08,889 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33672
2023-06-26 18:25:08,899 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40523', status: init, memory: 0, processing: 0>
2023-06-26 18:25:08,900 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40523
2023-06-26 18:25:08,900 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33686
2023-06-26 18:25:17,816 - distributed.scheduler - INFO - Receive client connection: Client-cd37e536-144e-11ee-a0cd-5cff35c1a711
2023-06-26 18:25:17,816 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:33846
2023-06-26 18:25:18,519 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 18:26:09,631 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 18:27:04,291 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 18:27:04,293 - distributed.scheduler - INFO - Restarting workers and releasing all keys.
2023-06-26 18:27:04,315 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33572; closing.
2023-06-26 18:27:04,315 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33431', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,315 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33431
2023-06-26 18:27:04,316 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:42922; closing.
2023-06-26 18:27:04,317 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33579', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,317 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33579
2023-06-26 18:27:04,317 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33616; closing.
2023-06-26 18:27:04,317 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35009', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,318 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35009
2023-06-26 18:27:04,318 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33668; closing.
2023-06-26 18:27:04,318 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35323', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,318 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35323
2023-06-26 18:27:04,319 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33652; closing.
2023-06-26 18:27:04,319 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:42944; closing.
2023-06-26 18:27:04,319 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39719', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,319 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39719
2023-06-26 18:27:04,319 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37517', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,319 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37517
2023-06-26 18:27:04,320 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33650; closing.
2023-06-26 18:27:04,320 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35357', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,320 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35357
2023-06-26 18:27:04,320 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33586; closing.
2023-06-26 18:27:04,321 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40159', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,321 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40159
2023-06-26 18:27:04,321 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33686; closing.
2023-06-26 18:27:04,321 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40523', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,321 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40523
2023-06-26 18:27:04,331 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33636; closing.
2023-06-26 18:27:04,331 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42449', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,331 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42449
2023-06-26 18:27:04,335 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:42896; closing.
2023-06-26 18:27:04,335 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41103', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,335 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41103
2023-06-26 18:27:04,339 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:42926; closing.
2023-06-26 18:27:04,339 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45131', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,340 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45131
2023-06-26 18:27:04,340 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33618; closing.
2023-06-26 18:27:04,340 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44457', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,340 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44457
2023-06-26 18:27:04,341 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33606; closing.
2023-06-26 18:27:04,341 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46633', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,341 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46633
2023-06-26 18:27:04,345 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33632; closing.
2023-06-26 18:27:04,345 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40533', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,345 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40533
2023-06-26 18:27:04,346 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33672; closing.
2023-06-26 18:27:04,346 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44331', status: closing, memory: 0, processing: 0>
2023-06-26 18:27:04,346 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44331
2023-06-26 18:27:04,346 - distributed.scheduler - INFO - Lost all workers
2023-06-26 18:27:15,088 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37663', status: init, memory: 0, processing: 0>
2023-06-26 18:27:15,088 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37663
2023-06-26 18:27:15,088 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47828
2023-06-26 18:27:15,922 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38171', status: init, memory: 0, processing: 0>
2023-06-26 18:27:15,922 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38171
2023-06-26 18:27:15,922 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47836
2023-06-26 18:27:16,037 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38245', status: init, memory: 0, processing: 0>
2023-06-26 18:27:16,037 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38245
2023-06-26 18:27:16,037 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47838
2023-06-26 18:27:16,059 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33821', status: init, memory: 0, processing: 0>
2023-06-26 18:27:16,059 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33821
2023-06-26 18:27:16,060 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47860
2023-06-26 18:27:16,060 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44703', status: init, memory: 0, processing: 0>
2023-06-26 18:27:16,060 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44703
2023-06-26 18:27:16,060 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47846
2023-06-26 18:27:16,239 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41113', status: init, memory: 0, processing: 0>
2023-06-26 18:27:16,240 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41113
2023-06-26 18:27:16,240 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:47880
2023-06-26 18:27:21,436 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44115', status: init, memory: 0, processing: 0>
2023-06-26 18:27:21,437 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44115
2023-06-26 18:27:21,437 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56040
2023-06-26 18:27:22,004 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42273', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,005 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42273
2023-06-26 18:27:22,005 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56056
2023-06-26 18:27:22,017 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40373', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,018 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40373
2023-06-26 18:27:22,018 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56064
2023-06-26 18:27:22,026 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39235', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,027 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39235
2023-06-26 18:27:22,027 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56066
2023-06-26 18:27:22,082 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42889', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,082 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42889
2023-06-26 18:27:22,082 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56084
2023-06-26 18:27:22,094 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35991', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,095 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35991
2023-06-26 18:27:22,095 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56096
2023-06-26 18:27:22,109 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46689', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,110 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46689
2023-06-26 18:27:22,110 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56080
2023-06-26 18:27:22,110 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33697', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,111 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33697
2023-06-26 18:27:22,111 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56106
2023-06-26 18:27:22,111 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44897', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,112 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44897
2023-06-26 18:27:22,112 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56086
2023-06-26 18:27:22,129 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46691', status: init, memory: 0, processing: 0>
2023-06-26 18:27:22,130 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46691
2023-06-26 18:27:22,130 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:56120
2023-06-26 18:27:22,316 - distributed.scheduler - INFO - Restarting finished.
2023-06-26 18:27:32,262 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 18:28:01,825 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 18:28:01,826 - distributed.scheduler - INFO - Remove client Client-cd37e536-144e-11ee-a0cd-5cff35c1a711
2023-06-26 18:28:01,826 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:33846; closing.
2023-06-26 18:28:01,826 - distributed.scheduler - INFO - Remove client Client-cd37e536-144e-11ee-a0cd-5cff35c1a711
2023-06-26 18:28:01,827 - distributed.scheduler - INFO - Close client connection: Client-cd37e536-144e-11ee-a0cd-5cff35c1a711
2023-06-26 18:35:47,651 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 18:35:47,651 - distributed.core - INFO - Connection to tcp://10.120.104.11:56120 has been closed.
2023-06-26 18:35:47,652 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46691', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,652 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46691
2023-06-26 18:35:47,654 - distributed.core - INFO - Connection to tcp://10.120.104.11:47838 has been closed.
2023-06-26 18:35:47,654 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38245', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,654 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38245
2023-06-26 18:35:47,654 - distributed.core - INFO - Connection to tcp://10.120.104.11:47846 has been closed.
2023-06-26 18:35:47,654 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44703', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,655 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44703
2023-06-26 18:35:47,655 - distributed.core - INFO - Connection to tcp://10.120.104.11:56064 has been closed.
2023-06-26 18:35:47,655 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40373', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,655 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40373
2023-06-26 18:35:47,655 - distributed.core - INFO - Connection to tcp://10.120.104.11:56086 has been closed.
2023-06-26 18:35:47,655 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44897', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,655 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44897
2023-06-26 18:35:47,655 - distributed.core - INFO - Connection to tcp://10.120.104.11:47860 has been closed.
2023-06-26 18:35:47,656 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33821', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,656 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33821
2023-06-26 18:35:47,656 - distributed.core - INFO - Connection to tcp://10.120.104.11:56040 has been closed.
2023-06-26 18:35:47,656 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44115', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,656 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44115
2023-06-26 18:35:47,656 - distributed.core - INFO - Connection to tcp://10.120.104.11:56084 has been closed.
2023-06-26 18:35:47,656 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42889', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,656 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42889
2023-06-26 18:35:47,656 - distributed.core - INFO - Connection to tcp://10.120.104.11:47880 has been closed.
2023-06-26 18:35:47,656 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41113', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,657 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41113
2023-06-26 18:35:47,657 - distributed.core - INFO - Connection to tcp://10.120.104.11:56096 has been closed.
2023-06-26 18:35:47,657 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35991', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,657 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35991
2023-06-26 18:35:47,657 - distributed.core - INFO - Connection to tcp://10.120.104.11:56106 has been closed.
2023-06-26 18:35:47,657 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33697', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,657 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33697
2023-06-26 18:35:47,657 - distributed.core - INFO - Connection to tcp://10.120.104.11:56056 has been closed.
2023-06-26 18:35:47,657 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42273', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,657 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42273
2023-06-26 18:35:47,657 - distributed.core - INFO - Connection to tcp://10.120.104.11:56080 has been closed.
2023-06-26 18:35:47,658 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46689', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,658 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46689
2023-06-26 18:35:47,658 - distributed.core - INFO - Connection to tcp://10.120.104.11:56066 has been closed.
2023-06-26 18:35:47,658 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39235', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,658 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39235
2023-06-26 18:35:47,658 - distributed.core - INFO - Connection to tcp://10.120.104.11:47836 has been closed.
2023-06-26 18:35:47,658 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38171', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,658 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38171
2023-06-26 18:35:47,658 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 18:35:47,659 - distributed.core - INFO - Connection to tcp://10.120.104.11:47828 has been closed.
2023-06-26 18:35:47,659 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37663', status: running, memory: 0, processing: 0>
2023-06-26 18:35:47,659 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37663
2023-06-26 18:35:47,659 - distributed.scheduler - INFO - Lost all workers
2023-06-26 18:35:47,659 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56106>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47860>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56096>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47828>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47828>: Stream is closed
2023-06-26 18:35:47,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47836>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47838>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,661 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56066>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56064>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47880>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56056>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56084>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56040>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:47846>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56086>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,662 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:56080>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 18:35:47,663 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 18:35:47,666 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 18:35:47,666 - distributed.scheduler - INFO - End scheduler
