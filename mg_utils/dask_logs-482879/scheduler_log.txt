RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 20:21:43,698 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:21:44,214 - distributed.scheduler - INFO - State start
2023-06-26 20:21:44,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-af3raj90', purging
2023-06-26 20:21:44,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-gdmha5qa', purging
2023-06-26 20:21:44,215 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-9h7ywaoa', purging
2023-06-26 20:21:44,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-hqbws4vh', purging
2023-06-26 20:21:44,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-7ypgqy74', purging
2023-06-26 20:21:44,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-qfmq3gic', purging
2023-06-26 20:21:44,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-duzwbn1q', purging
2023-06-26 20:21:44,216 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-rn38m3r7', purging
2023-06-26 20:21:44,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-tup9xs_v', purging
2023-06-26 20:21:44,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-4u6li9xj', purging
2023-06-26 20:21:44,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-52piktfd', purging
2023-06-26 20:21:44,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ibrsnd80', purging
2023-06-26 20:21:44,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-88h_64h8', purging
2023-06-26 20:21:44,217 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-_okz6tiw', purging
2023-06-26 20:21:44,218 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-dww8p5zk', purging
2023-06-26 20:21:44,230 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:21:44,231 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 20:21:44,231 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 20:22:03,454 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45079', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,458 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45079
2023-06-26 20:22:03,458 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36156
2023-06-26 20:22:03,514 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38067', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,515 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38067
2023-06-26 20:22:03,515 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36170
2023-06-26 20:22:03,602 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37467', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,602 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37467
2023-06-26 20:22:03,602 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36190
2023-06-26 20:22:03,603 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39767', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,603 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39767
2023-06-26 20:22:03,603 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36184
2023-06-26 20:22:03,694 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46027', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,694 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46027
2023-06-26 20:22:03,695 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36208
2023-06-26 20:22:03,695 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42139', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,696 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42139
2023-06-26 20:22:03,696 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36192
2023-06-26 20:22:03,709 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41153', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,709 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41153
2023-06-26 20:22:03,709 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36212
2023-06-26 20:22:03,722 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:37813', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,722 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:37813
2023-06-26 20:22:03,722 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36230
2023-06-26 20:22:03,728 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39107', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,728 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39107
2023-06-26 20:22:03,729 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36228
2023-06-26 20:22:03,737 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:36701', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,737 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:36701
2023-06-26 20:22:03,737 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36240
2023-06-26 20:22:03,747 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45307', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,748 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45307
2023-06-26 20:22:03,748 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36242
2023-06-26 20:22:03,757 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42803', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,757 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42803
2023-06-26 20:22:03,757 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36256
2023-06-26 20:22:03,758 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42115', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,758 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42115
2023-06-26 20:22:03,758 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36254
2023-06-26 20:22:03,770 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45957', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,770 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45957
2023-06-26 20:22:03,770 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36258
2023-06-26 20:22:03,776 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46639', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,777 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46639
2023-06-26 20:22:03,777 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36270
2023-06-26 20:22:03,791 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42953', status: init, memory: 0, processing: 0>
2023-06-26 20:22:03,791 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42953
2023-06-26 20:22:03,791 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36260
2023-06-26 20:22:07,589 - distributed.scheduler - INFO - Receive client connection: Client-1f5e2b34-145f-11ee-9fe5-5cff35c1a711
2023-06-26 20:22:07,590 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:36386
2023-06-26 20:22:08,287 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 20:23:28,249 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 20:23:49,694 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 20:23:49,696 - distributed.scheduler - INFO - Restarting workers and releasing all keys.
2023-06-26 20:23:49,719 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36240; closing.
2023-06-26 20:23:49,720 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:36701', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,720 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36701
2023-06-26 20:23:49,722 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36230; closing.
2023-06-26 20:23:49,722 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37813', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,722 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37813
2023-06-26 20:23:49,723 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36228; closing.
2023-06-26 20:23:49,723 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39107', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,724 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39107
2023-06-26 20:23:49,724 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36192; closing.
2023-06-26 20:23:49,725 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42139', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,725 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42139
2023-06-26 20:23:49,727 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36212; closing.
2023-06-26 20:23:49,727 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41153', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,727 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41153
2023-06-26 20:23:49,729 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36208; closing.
2023-06-26 20:23:49,729 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36242; closing.
2023-06-26 20:23:49,729 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36190; closing.
2023-06-26 20:23:49,729 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46027', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,729 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46027
2023-06-26 20:23:49,730 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45307', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,730 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45307
2023-06-26 20:23:49,730 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:37467', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,730 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:37467
2023-06-26 20:23:49,731 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36170; closing.
2023-06-26 20:23:49,731 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38067', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,731 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38067
2023-06-26 20:23:49,732 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:36170>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:23:49,733 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36260; closing.
2023-06-26 20:23:49,733 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42953', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,733 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42953
2023-06-26 20:23:49,737 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:36260>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:23:49,737 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36254; closing.
2023-06-26 20:23:49,738 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42115', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,738 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42115
2023-06-26 20:23:49,738 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36256; closing.
2023-06-26 20:23:49,738 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42803', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,739 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42803
2023-06-26 20:23:49,740 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36184; closing.
2023-06-26 20:23:49,740 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39767', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,740 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39767
2023-06-26 20:23:49,741 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36156; closing.
2023-06-26 20:23:49,742 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45079', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,742 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45079
2023-06-26 20:23:49,745 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36258; closing.
2023-06-26 20:23:49,745 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45957', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,745 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45957
2023-06-26 20:23:49,762 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36270; closing.
2023-06-26 20:23:49,762 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46639', status: closing, memory: 0, processing: 0>
2023-06-26 20:23:49,763 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46639
2023-06-26 20:23:49,763 - distributed.scheduler - INFO - Lost all workers
2023-06-26 20:23:59,590 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45471', status: init, memory: 0, processing: 0>
2023-06-26 20:23:59,590 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45471
2023-06-26 20:23:59,590 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40910
2023-06-26 20:24:02,195 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:36875', status: init, memory: 0, processing: 0>
2023-06-26 20:24:02,195 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:36875
2023-06-26 20:24:02,195 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40922
2023-06-26 20:24:02,215 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33557', status: init, memory: 0, processing: 0>
2023-06-26 20:24:02,215 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33557
2023-06-26 20:24:02,215 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:40924
2023-06-26 20:24:08,830 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:36401', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,830 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:36401
2023-06-26 20:24:08,830 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54348
2023-06-26 20:24:08,888 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46589', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,888 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46589
2023-06-26 20:24:08,888 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54366
2023-06-26 20:24:08,893 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:43493', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,894 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:43493
2023-06-26 20:24:08,894 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54362
2023-06-26 20:24:08,942 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42721', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,942 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42721
2023-06-26 20:24:08,942 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54374
2023-06-26 20:24:08,978 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33673', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,979 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33673
2023-06-26 20:24:08,979 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54388
2023-06-26 20:24:08,985 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44763', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,986 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44763
2023-06-26 20:24:08,986 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54400
2023-06-26 20:24:08,995 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42241', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,995 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42241
2023-06-26 20:24:08,995 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54406
2023-06-26 20:24:08,996 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45119', status: init, memory: 0, processing: 0>
2023-06-26 20:24:08,996 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45119
2023-06-26 20:24:08,996 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54418
2023-06-26 20:24:09,047 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35619', status: init, memory: 0, processing: 0>
2023-06-26 20:24:09,048 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35619
2023-06-26 20:24:09,048 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54424
2023-06-26 20:24:09,070 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42297', status: init, memory: 0, processing: 0>
2023-06-26 20:24:09,070 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42297
2023-06-26 20:24:09,071 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54430
2023-06-26 20:24:09,099 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38363', status: init, memory: 0, processing: 0>
2023-06-26 20:24:09,099 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38363
2023-06-26 20:24:09,099 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54432
2023-06-26 20:24:09,101 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46161', status: init, memory: 0, processing: 0>
2023-06-26 20:24:09,101 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46161
2023-06-26 20:24:09,101 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54456
2023-06-26 20:24:09,102 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:42999', status: init, memory: 0, processing: 0>
2023-06-26 20:24:09,102 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:42999
2023-06-26 20:24:09,102 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:54446
2023-06-26 20:24:09,201 - distributed.scheduler - INFO - Restarting finished.
2023-06-26 20:24:19,098 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 20:24:42,318 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-26 20:24:42,319 - distributed.scheduler - INFO - Remove client Client-1f5e2b34-145f-11ee-9fe5-5cff35c1a711
2023-06-26 20:24:42,319 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:36386; closing.
2023-06-26 20:24:42,320 - distributed.scheduler - INFO - Remove client Client-1f5e2b34-145f-11ee-9fe5-5cff35c1a711
2023-06-26 20:24:42,320 - distributed.scheduler - INFO - Close client connection: Client-1f5e2b34-145f-11ee-9fe5-5cff35c1a711
2023-06-26 20:25:46,701 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 20:25:46,702 - distributed.core - INFO - Connection to tcp://10.120.104.11:54406 has been closed.
2023-06-26 20:25:46,703 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42241', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,703 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42241
2023-06-26 20:25:46,703 - distributed.core - INFO - Connection to tcp://10.120.104.11:54446 has been closed.
2023-06-26 20:25:46,703 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42999', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,703 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42999
2023-06-26 20:25:46,704 - distributed.core - INFO - Connection to tcp://10.120.104.11:40910 has been closed.
2023-06-26 20:25:46,704 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45471', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,704 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45471
2023-06-26 20:25:46,704 - distributed.core - INFO - Connection to tcp://10.120.104.11:54432 has been closed.
2023-06-26 20:25:46,704 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38363', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,704 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38363
2023-06-26 20:25:46,704 - distributed.core - INFO - Connection to tcp://10.120.104.11:54374 has been closed.
2023-06-26 20:25:46,704 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42721', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,704 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42721
2023-06-26 20:25:46,704 - distributed.core - INFO - Connection to tcp://10.120.104.11:54362 has been closed.
2023-06-26 20:25:46,705 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:43493', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,705 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43493
2023-06-26 20:25:46,705 - distributed.core - INFO - Connection to tcp://10.120.104.11:54366 has been closed.
2023-06-26 20:25:46,705 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46589', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,705 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46589
2023-06-26 20:25:46,705 - distributed.core - INFO - Connection to tcp://10.120.104.11:54388 has been closed.
2023-06-26 20:25:46,705 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33673', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,705 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33673
2023-06-26 20:25:46,705 - distributed.core - INFO - Connection to tcp://10.120.104.11:54430 has been closed.
2023-06-26 20:25:46,705 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:42297', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,705 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:42297
2023-06-26 20:25:46,705 - distributed.core - INFO - Connection to tcp://10.120.104.11:54348 has been closed.
2023-06-26 20:25:46,705 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:36401', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,705 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36401
2023-06-26 20:25:46,706 - distributed.core - INFO - Connection to tcp://10.120.104.11:54400 has been closed.
2023-06-26 20:25:46,706 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44763', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,706 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44763
2023-06-26 20:25:46,706 - distributed.core - INFO - Connection to tcp://10.120.104.11:40922 has been closed.
2023-06-26 20:25:46,706 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:36875', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,706 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36875
2023-06-26 20:25:46,706 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 20:25:46,707 - distributed.core - INFO - Connection to tcp://10.120.104.11:40924 has been closed.
2023-06-26 20:25:46,707 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33557', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,707 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33557
2023-06-26 20:25:46,707 - distributed.core - INFO - Connection to tcp://10.120.104.11:54424 has been closed.
2023-06-26 20:25:46,707 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35619', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,707 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35619
2023-06-26 20:25:46,707 - distributed.core - INFO - Connection to tcp://10.120.104.11:54418 has been closed.
2023-06-26 20:25:46,708 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45119', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,708 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45119
2023-06-26 20:25:46,708 - distributed.core - INFO - Connection to tcp://10.120.104.11:54456 has been closed.
2023-06-26 20:25:46,708 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46161', status: running, memory: 0, processing: 0>
2023-06-26 20:25:46,708 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46161
2023-06-26 20:25:46,708 - distributed.scheduler - INFO - Lost all workers
2023-06-26 20:25:46,708 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:40924>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:25:46,708 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:54424>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:25:46,708 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:54418>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:25:46,709 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:54456>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:25:46,709 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 20:25:46,712 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 20:25:46,712 - distributed.scheduler - INFO - End scheduler
