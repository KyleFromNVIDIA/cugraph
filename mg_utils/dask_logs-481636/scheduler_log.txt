RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 20:20:21,551 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:20:22,072 - distributed.scheduler - INFO - State start
2023-06-26 20:20:22,073 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3m6vs3pv', purging
2023-06-26 20:20:22,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-x1c7cefs', purging
2023-06-26 20:20:22,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-pxg02qrj', purging
2023-06-26 20:20:22,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-z86w3tud', purging
2023-06-26 20:20:22,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-qxs6e255', purging
2023-06-26 20:20:22,074 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-kojakd46', purging
2023-06-26 20:20:22,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-mb1rjgbq', purging
2023-06-26 20:20:22,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-zqz84jm6', purging
2023-06-26 20:20:22,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-rm0dmyvz', purging
2023-06-26 20:20:22,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-dam3fn3_', purging
2023-06-26 20:20:22,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-jpy_3wae', purging
2023-06-26 20:20:22,075 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-s3ny85x4', purging
2023-06-26 20:20:22,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ha0iqpyn', purging
2023-06-26 20:20:22,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-1ztjfs5o', purging
2023-06-26 20:20:22,076 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-hb9e6flw', purging
2023-06-26 20:20:22,088 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:20:22,089 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 20:20:22,089 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 20:20:41,146 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40231', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,148 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40231
2023-06-26 20:20:41,148 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46512
2023-06-26 20:20:41,188 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38399', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,188 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38399
2023-06-26 20:20:41,188 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46516
2023-06-26 20:20:41,229 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:43623', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,229 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:43623
2023-06-26 20:20:41,229 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46528
2023-06-26 20:20:41,246 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:36069', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,246 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:36069
2023-06-26 20:20:41,246 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46534
2023-06-26 20:20:41,308 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34265', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34265
2023-06-26 20:20:41,309 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46550
2023-06-26 20:20:41,341 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33317', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,341 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33317
2023-06-26 20:20:41,341 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46558
2023-06-26 20:20:41,399 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44009', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,400 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44009
2023-06-26 20:20:41,400 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46572
2023-06-26 20:20:41,416 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46723', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,416 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46723
2023-06-26 20:20:41,416 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46588
2023-06-26 20:20:41,422 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:43051', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,422 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:43051
2023-06-26 20:20:41,422 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46604
2023-06-26 20:20:41,430 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41435', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,431 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41435
2023-06-26 20:20:41,431 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46612
2023-06-26 20:20:41,438 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39687', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,438 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39687
2023-06-26 20:20:41,438 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46626
2023-06-26 20:20:41,439 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:39783', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,440 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:39783
2023-06-26 20:20:41,440 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46632
2023-06-26 20:20:41,464 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45819', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,464 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45819
2023-06-26 20:20:41,464 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46646
2023-06-26 20:20:41,466 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44011', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,467 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44011
2023-06-26 20:20:41,467 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46650
2023-06-26 20:20:41,477 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:44575', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,477 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:44575
2023-06-26 20:20:41,477 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46654
2023-06-26 20:20:41,483 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:43187', status: init, memory: 0, processing: 0>
2023-06-26 20:20:41,483 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:43187
2023-06-26 20:20:41,483 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:46656
2023-06-26 20:21:30,510 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 20:21:30,512 - distributed.core - INFO - Connection to tcp://10.120.104.11:46646 has been closed.
2023-06-26 20:21:30,513 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45819', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,513 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45819
2023-06-26 20:21:30,514 - distributed.core - INFO - Connection to tcp://10.120.104.11:46534 has been closed.
2023-06-26 20:21:30,514 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:36069', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,514 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:36069
2023-06-26 20:21:30,515 - distributed.core - INFO - Connection to tcp://10.120.104.11:46612 has been closed.
2023-06-26 20:21:30,515 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41435', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,515 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41435
2023-06-26 20:21:30,515 - distributed.core - INFO - Connection to tcp://10.120.104.11:46604 has been closed.
2023-06-26 20:21:30,515 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:43051', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,515 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43051
2023-06-26 20:21:30,515 - distributed.core - INFO - Connection to tcp://10.120.104.11:46558 has been closed.
2023-06-26 20:21:30,515 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33317', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,515 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33317
2023-06-26 20:21:30,516 - distributed.core - INFO - Connection to tcp://10.120.104.11:46572 has been closed.
2023-06-26 20:21:30,517 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44009', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,517 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44009
2023-06-26 20:21:30,517 - distributed.core - INFO - Connection to tcp://10.120.104.11:46654 has been closed.
2023-06-26 20:21:30,517 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44575', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,517 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44575
2023-06-26 20:21:30,517 - distributed.core - INFO - Connection to tcp://10.120.104.11:46650 has been closed.
2023-06-26 20:21:30,517 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:44011', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,517 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:44011
2023-06-26 20:21:30,517 - distributed.core - INFO - Connection to tcp://10.120.104.11:46632 has been closed.
2023-06-26 20:21:30,517 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39783', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,517 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39783
2023-06-26 20:21:30,518 - distributed.core - INFO - Connection to tcp://10.120.104.11:46516 has been closed.
2023-06-26 20:21:30,518 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38399', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,518 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38399
2023-06-26 20:21:30,518 - distributed.core - INFO - Connection to tcp://10.120.104.11:46656 has been closed.
2023-06-26 20:21:30,518 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:43187', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,518 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43187
2023-06-26 20:21:30,518 - distributed.core - INFO - Connection to tcp://10.120.104.11:46512 has been closed.
2023-06-26 20:21:30,518 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40231', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,518 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40231
2023-06-26 20:21:30,518 - distributed.core - INFO - Connection to tcp://10.120.104.11:46550 has been closed.
2023-06-26 20:21:30,518 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34265', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,518 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34265
2023-06-26 20:21:30,519 - distributed.core - INFO - Connection to tcp://10.120.104.11:46626 has been closed.
2023-06-26 20:21:30,519 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:39687', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,519 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:39687
2023-06-26 20:21:30,519 - distributed.core - INFO - Connection to tcp://10.120.104.11:46528 has been closed.
2023-06-26 20:21:30,519 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:43623', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,519 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43623
2023-06-26 20:21:30,519 - distributed.core - INFO - Connection to tcp://10.120.104.11:46588 has been closed.
2023-06-26 20:21:30,519 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46723', status: running, memory: 0, processing: 0>
2023-06-26 20:21:30,519 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46723
2023-06-26 20:21:30,519 - distributed.scheduler - INFO - Lost all workers
2023-06-26 20:21:30,519 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 20:21:30,520 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46550>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,522 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46516>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,522 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46626>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,522 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46632>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46512>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46656>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46528>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46572>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46650>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46654>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,523 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:46588>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:21:30,524 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 20:21:30,527 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 20:21:30,527 - distributed.scheduler - INFO - End scheduler
