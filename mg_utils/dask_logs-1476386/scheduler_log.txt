RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/work/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-22 22:38:51,243 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 22:38:51,701 - distributed.scheduler - INFO - State start
2023-06-22 22:38:51,702 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-086ssx62', purging
2023-06-22 22:38:51,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-10n4uwkl', purging
2023-06-22 22:38:51,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-71zxu_rx', purging
2023-06-22 22:38:51,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-loqoyg0z', purging
2023-06-22 22:38:51,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-nsansl7i', purging
2023-06-22 22:38:51,703 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-hn77gjob', purging
2023-06-22 22:38:51,704 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-cun0p8jg', purging
2023-06-22 22:38:51,712 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 22:38:51,713 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.169:8786
2023-06-22 22:38:51,713 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.169:8787/status
2023-06-22 22:39:01,753 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:41655', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,018 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:41655
2023-06-22 22:39:02,018 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43628
2023-06-22 22:39:02,790 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:45291', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,790 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:45291
2023-06-22 22:39:02,791 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43638
2023-06-22 22:39:02,792 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:34397', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,792 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:34397
2023-06-22 22:39:02,792 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43642
2023-06-22 22:39:02,793 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:36837', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,793 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:36837
2023-06-22 22:39:02,794 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43658
2023-06-22 22:39:02,795 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:37635', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,796 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:37635
2023-06-22 22:39:02,796 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43672
2023-06-22 22:39:02,797 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:40099', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,798 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:40099
2023-06-22 22:39:02,798 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43662
2023-06-22 22:39:02,799 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:40447', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,799 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:40447
2023-06-22 22:39:02,799 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43640
2023-06-22 22:39:02,800 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:39515', status: init, memory: 0, processing: 0>
2023-06-22 22:39:02,801 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:39515
2023-06-22 22:39:02,801 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43680
2023-06-22 22:39:05,170 - distributed.scheduler - INFO - Receive client connection: Client-97c717aa-114d-11ee-87a1-d8c49778ced7
2023-06-22 22:39:05,170 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:43760
2023-06-22 22:39:05,254 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-22 22:39:27,133 - distributed.scheduler - INFO - Remove client Client-97c717aa-114d-11ee-87a1-d8c49778ced7
2023-06-22 22:39:27,133 - distributed.core - INFO - Received 'close-stream' from tcp://10.33.227.169:43760; closing.
2023-06-22 22:39:27,133 - distributed.scheduler - INFO - Remove client Client-97c717aa-114d-11ee-87a1-d8c49778ced7
2023-06-22 22:39:27,134 - distributed.scheduler - INFO - Close client connection: Client-97c717aa-114d-11ee-87a1-d8c49778ced7
2023-06-22 22:39:32,389 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-22 22:39:32,390 - distributed.core - INFO - Connection to tcp://10.33.227.169:43640 has been closed.
2023-06-22 22:39:32,390 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:40447', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,391 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:40447
2023-06-22 22:39:32,391 - distributed.core - INFO - Connection to tcp://10.33.227.169:43672 has been closed.
2023-06-22 22:39:32,392 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:37635', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,392 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:37635
2023-06-22 22:39:32,392 - distributed.core - INFO - Connection to tcp://10.33.227.169:43662 has been closed.
2023-06-22 22:39:32,392 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:40099', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,392 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:40099
2023-06-22 22:39:32,392 - distributed.core - INFO - Connection to tcp://10.33.227.169:43680 has been closed.
2023-06-22 22:39:32,393 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:39515', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,393 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:39515
2023-06-22 22:39:32,393 - distributed.core - INFO - Connection to tcp://10.33.227.169:43638 has been closed.
2023-06-22 22:39:32,393 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:45291', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,393 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:45291
2023-06-22 22:39:32,394 - distributed.scheduler - INFO - Scheduler closing...
2023-06-22 22:39:32,395 - distributed.core - INFO - Connection to tcp://10.33.227.169:43628 has been closed.
2023-06-22 22:39:32,395 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:41655', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,395 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:41655
2023-06-22 22:39:32,395 - distributed.core - INFO - Connection to tcp://10.33.227.169:43642 has been closed.
2023-06-22 22:39:32,395 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:34397', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,395 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:34397
2023-06-22 22:39:32,396 - distributed.core - INFO - Connection to tcp://10.33.227.169:43658 has been closed.
2023-06-22 22:39:32,396 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:36837', status: running, memory: 0, processing: 0>
2023-06-22 22:39:32,396 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:36837
2023-06-22 22:39:32,396 - distributed.scheduler - INFO - Lost all workers
2023-06-22 22:39:32,396 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:43642>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 22:39:32,398 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:43658>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 22:39:32,398 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:43628>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 22:39:32,399 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-22 22:39:32,402 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.169:8786'
2023-06-22 22:39:32,402 - distributed.scheduler - INFO - End scheduler
