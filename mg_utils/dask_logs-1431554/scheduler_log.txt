RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/work/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-22 21:38:09,687 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 21:38:10,166 - distributed.scheduler - INFO - State start
2023-06-22 21:38:10,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-pbu1v498', purging
2023-06-22 21:38:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-znhmr3ol', purging
2023-06-22 21:38:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-7w426qu3', purging
2023-06-22 21:38:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-6je64mww', purging
2023-06-22 21:38:10,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-emlpjr2w', purging
2023-06-22 21:38:10,169 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-o4goj21c', purging
2023-06-22 21:38:10,178 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-22 21:38:10,179 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.169:8786
2023-06-22 21:38:10,179 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.169:8787/status
2023-06-22 21:38:21,482 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:46401', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,825 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:46401
2023-06-22 21:38:21,825 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60086
2023-06-22 21:38:21,836 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:41049', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,837 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:41049
2023-06-22 21:38:21,837 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60090
2023-06-22 21:38:21,838 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:45261', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,838 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:45261
2023-06-22 21:38:21,838 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60128
2023-06-22 21:38:21,839 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:33253', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,839 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:33253
2023-06-22 21:38:21,839 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60126
2023-06-22 21:38:21,840 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:41393', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,841 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:41393
2023-06-22 21:38:21,841 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60100
2023-06-22 21:38:21,841 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:46761', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,841 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:46761
2023-06-22 21:38:21,841 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60110
2023-06-22 21:38:21,842 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:41941', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,843 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:41941
2023-06-22 21:38:21,843 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60142
2023-06-22 21:38:21,843 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.33.227.169:46767', status: init, memory: 0, processing: 0>
2023-06-22 21:38:21,844 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.33.227.169:46767
2023-06-22 21:38:21,844 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:60152
2023-06-22 21:38:44,093 - distributed.scheduler - INFO - Receive client connection: Client-2972b676-1145-11ee-9b1f-d8c49778ced7
2023-06-22 21:38:44,094 - distributed.core - INFO - Starting established connection to tcp://10.33.227.169:37598
2023-06-22 21:38:44,182 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-22 21:39:33,274 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 21:39:35,703 - distributed.worker - INFO - Run out-of-band function 'lambda'
2023-06-22 21:39:39,565 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-22 21:39:44,246 - distributed.worker - INFO - Run out-of-band function '_func_destroy_scheduler_session'
2023-06-22 21:39:44,248 - distributed.scheduler - INFO - Remove client Client-2972b676-1145-11ee-9b1f-d8c49778ced7
2023-06-22 21:39:44,255 - distributed.core - INFO - Received 'close-stream' from tcp://10.33.227.169:37598; closing.
2023-06-22 21:39:44,255 - distributed.scheduler - INFO - Remove client Client-2972b676-1145-11ee-9b1f-d8c49778ced7
2023-06-22 21:39:44,257 - distributed.scheduler - INFO - Close client connection: Client-2972b676-1145-11ee-9b1f-d8c49778ced7
2023-06-22 21:43:19,548 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-22 21:43:19,548 - distributed.scheduler - INFO - Scheduler closing...
2023-06-22 21:43:19,549 - distributed.core - INFO - Connection to tcp://10.33.227.169:60152 has been closed.
2023-06-22 21:43:19,549 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:46767', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,549 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:46767
2023-06-22 21:43:19,550 - distributed.core - INFO - Connection to tcp://10.33.227.169:60128 has been closed.
2023-06-22 21:43:19,550 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:45261', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,550 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:45261
2023-06-22 21:43:19,552 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-22 21:43:19,552 - distributed.core - INFO - Connection to tcp://10.33.227.169:60142 has been closed.
2023-06-22 21:43:19,553 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:41941', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,553 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:41941
2023-06-22 21:43:19,553 - distributed.core - INFO - Connection to tcp://10.33.227.169:60090 has been closed.
2023-06-22 21:43:19,553 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:41049', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,553 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:41049
2023-06-22 21:43:19,553 - distributed.core - INFO - Connection to tcp://10.33.227.169:60100 has been closed.
2023-06-22 21:43:19,554 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:41393', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,554 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:41393
2023-06-22 21:43:19,554 - distributed.core - INFO - Connection to tcp://10.33.227.169:60110 has been closed.
2023-06-22 21:43:19,554 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:46761', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,554 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:46761
2023-06-22 21:43:19,554 - distributed.core - INFO - Connection to tcp://10.33.227.169:60126 has been closed.
2023-06-22 21:43:19,555 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:33253', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,555 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:33253
2023-06-22 21:43:19,555 - distributed.core - INFO - Connection to tcp://10.33.227.169:60086 has been closed.
2023-06-22 21:43:19,555 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.33.227.169:46401', status: running, memory: 0, processing: 0>
2023-06-22 21:43:19,555 - distributed.core - INFO - Removing comms to tcp://10.33.227.169:46401
2023-06-22 21:43:19,555 - distributed.scheduler - INFO - Lost all workers
2023-06-22 21:43:19,555 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60126>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60126>: Stream is closed
2023-06-22 21:43:19,557 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60090>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60090>: Stream is closed
2023-06-22 21:43:19,557 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60100>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60100>: Stream is closed
2023-06-22 21:43:19,557 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60142>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60142>: Stream is closed
2023-06-22 21:43:19,557 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60128>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-22 21:43:19,558 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60086>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60086>: Stream is closed
2023-06-22 21:43:19,558 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60110>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.33.227.169:8786 remote=tcp://10.33.227.169:60110>: Stream is closed
2023-06-22 21:43:19,561 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.169:8786'
2023-06-22 21:43:19,561 - distributed.scheduler - INFO - End scheduler
