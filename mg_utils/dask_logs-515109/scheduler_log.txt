RUNNING: "python -m distributed.cli.dask_scheduler --protocol=tcp
                    --scheduler-file /root/cugraph/mg_utils/dask-scheduler.json
                "
/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:140: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead
  warnings.warn(
2023-06-26 20:52:21,298 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:52:21,813 - distributed.scheduler - INFO - State start
2023-06-26 20:52:21,814 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-adaz7gic', purging
2023-06-26 20:52:21,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-y6m674uv', purging
2023-06-26 20:52:21,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-toq8xqnh', purging
2023-06-26 20:52:21,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-x_ve27ev', purging
2023-06-26 20:52:21,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-nvu8qa_n', purging
2023-06-26 20:52:21,815 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-djp6ioc6', purging
2023-06-26 20:52:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-8yyqoabo', purging
2023-06-26 20:52:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-l_7sh3tb', purging
2023-06-26 20:52:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-i2yokw8z', purging
2023-06-26 20:52:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-9kgns5sa', purging
2023-06-26 20:52:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-itl2vk0f', purging
2023-06-26 20:52:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ik_x5b86', purging
2023-06-26 20:52:21,817 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-x9tbvh0a', purging
2023-06-26 20:52:21,817 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-l7s3d1hv', purging
2023-06-26 20:52:21,817 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-g43jp9kt', purging
2023-06-26 20:52:21,817 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-f5gc8irf', purging
2023-06-26 20:52:21,829 - distributed.scheduler - INFO - -----------------------------------------------
2023-06-26 20:52:21,830 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.120.104.11:8786
2023-06-26 20:52:21,830 - distributed.scheduler - INFO -   dashboard at:  http://10.120.104.11:8787/status
2023-06-26 20:52:40,746 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46205', status: init, memory: 0, processing: 0>
2023-06-26 20:52:40,748 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46205
2023-06-26 20:52:40,748 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32836
2023-06-26 20:52:40,925 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:43897', status: init, memory: 0, processing: 0>
2023-06-26 20:52:40,926 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:43897
2023-06-26 20:52:40,926 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32850
2023-06-26 20:52:41,056 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:33241', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,057 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:33241
2023-06-26 20:52:41,057 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32852
2023-06-26 20:52:41,198 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:38927', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,198 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:38927
2023-06-26 20:52:41,198 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32856
2023-06-26 20:52:41,212 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35861', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,213 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35861
2023-06-26 20:52:41,213 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32858
2023-06-26 20:52:41,223 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40309', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,224 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40309
2023-06-26 20:52:41,224 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32866
2023-06-26 20:52:41,275 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45723', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,275 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45723
2023-06-26 20:52:41,275 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32880
2023-06-26 20:52:41,297 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40585', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,297 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40585
2023-06-26 20:52:41,297 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32894
2023-06-26 20:52:41,312 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35025', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,312 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35025
2023-06-26 20:52:41,312 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32908
2023-06-26 20:52:41,356 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46073', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,356 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46073
2023-06-26 20:52:41,356 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32912
2023-06-26 20:52:41,414 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:41703', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,415 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:41703
2023-06-26 20:52:41,415 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32922
2023-06-26 20:52:41,426 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:35789', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,426 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:35789
2023-06-26 20:52:41,426 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32932
2023-06-26 20:52:41,437 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:45865', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,437 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:45865
2023-06-26 20:52:41,437 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32940
2023-06-26 20:52:41,470 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:34659', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,470 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:34659
2023-06-26 20:52:41,470 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32946
2023-06-26 20:52:41,474 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:46665', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,474 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:46665
2023-06-26 20:52:41,474 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32942
2023-06-26 20:52:41,485 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.120.104.11:40825', status: init, memory: 0, processing: 0>
2023-06-26 20:52:41,485 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.120.104.11:40825
2023-06-26 20:52:41,485 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:32962
2023-06-26 20:53:01,327 - distributed.scheduler - INFO - Receive client connection: Client-70482d48-1463-11ee-9ed1-5cff35c1a711
2023-06-26 20:53:01,327 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:41596
2023-06-26 20:53:02,064 - distributed.worker - INFO - Run out-of-band function '_func_set_scheduler_as_nccl_root'
2023-06-26 20:53:53,731 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-06-26 20:54:10,461 - distributed.scheduler - INFO - Remove client Client-70482d48-1463-11ee-9ed1-5cff35c1a711
2023-06-26 20:54:10,462 - distributed.core - INFO - Received 'close-stream' from tcp://10.120.104.11:41596; closing.
2023-06-26 20:54:10,462 - distributed.scheduler - INFO - Remove client Client-70482d48-1463-11ee-9ed1-5cff35c1a711
2023-06-26 20:54:10,462 - distributed.scheduler - INFO - Close client connection: Client-70482d48-1463-11ee-9ed1-5cff35c1a711
2023-06-26 20:54:16,983 - distributed._signals - INFO - Received signal SIGINT (2)
2023-06-26 20:54:16,983 - distributed.core - INFO - Connection to tcp://10.120.104.11:32932 has been closed.
2023-06-26 20:54:16,983 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35789', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,984 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35789
2023-06-26 20:54:16,984 - distributed.core - INFO - Connection to tcp://10.120.104.11:32908 has been closed.
2023-06-26 20:54:16,984 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35025', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,984 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35025
2023-06-26 20:54:16,985 - distributed.core - INFO - Connection to tcp://10.120.104.11:32962 has been closed.
2023-06-26 20:54:16,985 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40825', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,985 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40825
2023-06-26 20:54:16,985 - distributed.scheduler - INFO - Scheduler closing...
2023-06-26 20:54:16,986 - distributed.core - INFO - Connection to tcp://10.120.104.11:32850 has been closed.
2023-06-26 20:54:16,986 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:43897', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,986 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:43897
2023-06-26 20:54:16,986 - distributed.core - INFO - Connection to tcp://10.120.104.11:32946 has been closed.
2023-06-26 20:54:16,986 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:34659', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,986 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:34659
2023-06-26 20:54:16,986 - distributed.core - INFO - Connection to tcp://10.120.104.11:32866 has been closed.
2023-06-26 20:54:16,986 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40309', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,986 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40309
2023-06-26 20:54:16,987 - distributed.core - INFO - Connection to tcp://10.120.104.11:32836 has been closed.
2023-06-26 20:54:16,987 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46205', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,987 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46205
2023-06-26 20:54:16,987 - distributed.core - INFO - Connection to tcp://10.120.104.11:32912 has been closed.
2023-06-26 20:54:16,987 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46073', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,987 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46073
2023-06-26 20:54:16,987 - distributed.core - INFO - Connection to tcp://10.120.104.11:32852 has been closed.
2023-06-26 20:54:16,987 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:33241', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,987 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:33241
2023-06-26 20:54:16,987 - distributed.core - INFO - Connection to tcp://10.120.104.11:32942 has been closed.
2023-06-26 20:54:16,987 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:46665', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,987 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:46665
2023-06-26 20:54:16,988 - distributed.core - INFO - Connection to tcp://10.120.104.11:32940 has been closed.
2023-06-26 20:54:16,988 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45865', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,988 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45865
2023-06-26 20:54:16,988 - distributed.core - INFO - Connection to tcp://10.120.104.11:32922 has been closed.
2023-06-26 20:54:16,988 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:41703', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,989 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:41703
2023-06-26 20:54:16,989 - distributed.core - INFO - Connection to tcp://10.120.104.11:32856 has been closed.
2023-06-26 20:54:16,989 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:38927', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,989 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:38927
2023-06-26 20:54:16,989 - distributed.core - INFO - Connection to tcp://10.120.104.11:32894 has been closed.
2023-06-26 20:54:16,989 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:40585', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,989 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:40585
2023-06-26 20:54:16,989 - distributed.core - INFO - Connection to tcp://10.120.104.11:32880 has been closed.
2023-06-26 20:54:16,989 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:45723', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,989 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:45723
2023-06-26 20:54:16,989 - distributed.core - INFO - Connection to tcp://10.120.104.11:32858 has been closed.
2023-06-26 20:54:16,989 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.120.104.11:35861', status: running, memory: 0, processing: 0>
2023-06-26 20:54:16,989 - distributed.core - INFO - Removing comms to tcp://10.120.104.11:35861
2023-06-26 20:54:16,990 - distributed.scheduler - INFO - Lost all workers
2023-06-26 20:54:16,990 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32852>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32946>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32858>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32858>: Stream is closed
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32856>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32856>: Stream is closed
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32866>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32894>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32894>: Stream is closed
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32922>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32922>: Stream is closed
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32850>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,991 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32880>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32880>: Stream is closed
2023-06-26 20:54:16,992 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32940>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 317, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 328, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 144, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32940>: Stream is closed
2023-06-26 20:54:16,992 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32912>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,992 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32836>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,992 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://10.120.104.11:8786 remote=tcp://10.120.104.11:32942>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/comm/tcp.py", line 269, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2023-06-26 20:54:16,992 - distributed.scheduler - INFO - Scheduler closing all comms
2023-06-26 20:54:16,995 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.120.104.11:8786'
2023-06-26 20:54:16,995 - distributed.scheduler - INFO - End scheduler
